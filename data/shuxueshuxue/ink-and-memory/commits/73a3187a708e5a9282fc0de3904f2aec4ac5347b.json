{
  "sha": "73a3187a708e5a9282fc0de3904f2aec4ac5347b",
  "node_id": "C_kwDOP2Zrm9oAKDczYTMxODdhNzA4ZTVhOTI4MmZjMGRlMzkwNGYyYWVjNGFjNTM0N2I",
  "commit": {
    "author": {
      "name": "lexicalmathical",
      "email": "lexicalmathical@gmail.com",
      "date": "2025-11-18T03:01:22Z"
    },
    "committer": {
      "name": "lexicalmathical",
      "email": "lexicalmathical@gmail.com",
      "date": "2025-11-18T03:01:22Z"
    },
    "message": "Add timeline auto-generation scheduler with asyncio.run() fix\n\nImplements automatic timeline image generation at midnight (Beijing time)\nfor all users with activity on the previous day. Concurrent generation\nwith rate limiting (max 5 concurrent).\n\nChanges:\n- backend/database.py: Add timezone-aware helpers\n  - get_users_with_activity_on_date(): Find users with sessions on date\n  - extract_text_from_sessions_on_date(): Extract text from date-filtered sessions\n  - Both convert Beijing local time to UTC for database queries\n\n- backend/scheduler.py: New async scheduler module\n  - generate_for_user(): Single user generation with idempotency\n  - generate_timeline_images_for_date(): Batch generation with Semaphore\n  - daily_generation_job(): Scheduled job wrapper\n  - Uses asyncio.Semaphore for rate limiting (max 5 concurrent)\n\n- backend/server.py: APScheduler integration\n  - Add AsyncIOScheduler with midnight cron trigger\n  - Update generate_daily_picture() to accept optional target_date param\n  - Add /api/admin/trigger-timeline-generation endpoint for manual testing\n  - Fix: Use asyncio.run() to create event loop for scheduler thread\n\nTested successfully:\n- Scheduler triggers at configured time\n- Finds users with activity on target date\n- Skips users with existing images (idempotency)\n- Generates new images concurrently\n- Stats: 2 total, 1 success, 1 skipped, 0 failed",
    "tree": {
      "sha": "8aa4cb1ce907dbd9fa4a8ebe7e394823a2e6971b",
      "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/git/trees/8aa4cb1ce907dbd9fa4a8ebe7e394823a2e6971b"
    },
    "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/git/commits/73a3187a708e5a9282fc0de3904f2aec4ac5347b",
    "comment_count": 0,
    "verification": {
      "verified": false,
      "reason": "unsigned",
      "signature": null,
      "payload": null,
      "verified_at": null
    }
  },
  "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/73a3187a708e5a9282fc0de3904f2aec4ac5347b",
  "html_url": "https://github.com/shuxueshuxue/ink-and-memory/commit/73a3187a708e5a9282fc0de3904f2aec4ac5347b",
  "comments_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/73a3187a708e5a9282fc0de3904f2aec4ac5347b/comments",
  "author": null,
  "committer": null,
  "parents": [
    {
      "sha": "7a8675a8e78764848a1ceb6eaa99aba33456ec21",
      "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/7a8675a8e78764848a1ceb6eaa99aba33456ec21",
      "html_url": "https://github.com/shuxueshuxue/ink-and-memory/commit/7a8675a8e78764848a1ceb6eaa99aba33456ec21"
    }
  ],
  "stats": {
    "total": 381,
    "additions": 378,
    "deletions": 3
  },
  "files": [
    {
      "sha": "a15a2bdc58b0a46ae24af563e1d328fbdb23b38a",
      "filename": "backend/database.py",
      "status": "modified",
      "additions": 118,
      "deletions": 0,
      "changes": 118,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fdatabase.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fdatabase.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fdatabase.py?ref=73a3187a708e5a9282fc0de3904f2aec4ac5347b",
      "patch": "@@ -946,6 +946,124 @@ def delete_session(user_id: int, session_id: str):\n     finally:\n         db.close()\n \n+# ========== Timeline Auto-Generation Helpers ==========\n+\n+def get_users_with_activity_on_date(target_date: str, timezone: str = 'Asia/Shanghai') -> list[int]:\n+    \"\"\"\n+    Get user IDs who updated sessions on target_date (local timezone).\n+\n+    Args:\n+        target_date: Date string in YYYY-MM-DD format (local timezone)\n+        timezone: Timezone name (default: Asia/Shanghai for Beijing)\n+\n+    Returns:\n+        List of user_ids with non-empty sessions on that date\n+\n+    @@@ Timezone handling - SQLite stores UTC, we convert to local timezone for date matching\n+    \"\"\"\n+    from datetime import datetime\n+    from zoneinfo import ZoneInfo\n+\n+    db = get_db()\n+    try:\n+        # @@@ Convert target_date (local) to UTC range for database query\n+        # Example: 2025-01-17 in Beijing = 2025-01-16 16:00 UTC to 2025-01-17 16:00 UTC\n+        tz = ZoneInfo(timezone)\n+        local_date = datetime.strptime(target_date, '%Y-%m-%d').replace(tzinfo=tz)\n+\n+        # Get start and end of day in UTC\n+        start_of_day_local = local_date.replace(hour=0, minute=0, second=0, microsecond=0)\n+        end_of_day_local = local_date.replace(hour=23, minute=59, second=59, microsecond=999999)\n+\n+        start_utc = start_of_day_local.astimezone(ZoneInfo('UTC'))\n+        end_utc = end_of_day_local.astimezone(ZoneInfo('UTC'))\n+\n+        # Query sessions updated in this UTC range\n+        rows = db.execute(\"\"\"\n+            SELECT DISTINCT user_id, editor_state_json\n+            FROM user_sessions\n+            WHERE updated_at >= ? AND updated_at <= ?\n+        \"\"\", (start_utc.isoformat(), end_utc.isoformat())).fetchall()\n+\n+        # Filter users with non-empty content\n+        user_ids = []\n+        for row in rows:\n+            try:\n+                state = json.loads(row['editor_state_json'])\n+                # Check if has any text cells with content\n+                has_content = any(\n+                    cell.get('type') == 'text' and cell.get('content', '').strip()\n+                    for cell in state.get('cells', [])\n+                )\n+                if has_content and row['user_id'] not in user_ids:\n+                    user_ids.append(row['user_id'])\n+            except (json.JSONDecodeError, KeyError):\n+                continue\n+\n+        return user_ids\n+    finally:\n+        db.close()\n+\n+def extract_text_from_sessions_on_date(user_id: int, target_date: str, timezone: str = 'Asia/Shanghai') -> str:\n+    \"\"\"\n+    Extract all text from user's sessions updated on target_date (local timezone).\n+\n+    Args:\n+        user_id: User ID\n+        target_date: Date string in YYYY-MM-DD format (local timezone)\n+        timezone: Timezone name (default: Asia/Shanghai for Beijing)\n+\n+    Returns:\n+        Concatenated text from all text cells, joined with double newlines\n+\n+    @@@ Replicates frontend's getAllNotesFromSessions() logic but date-filtered\n+    @@@ Timezone handling - SQLite stores UTC, we convert to local timezone for date matching\n+    \"\"\"\n+    from datetime import datetime\n+    from zoneinfo import ZoneInfo\n+\n+    db = get_db()\n+    try:\n+        # @@@ Convert target_date (local) to UTC range for database query\n+        tz = ZoneInfo(timezone)\n+        local_date = datetime.strptime(target_date, '%Y-%m-%d').replace(tzinfo=tz)\n+\n+        start_of_day_local = local_date.replace(hour=0, minute=0, second=0, microsecond=0)\n+        end_of_day_local = local_date.replace(hour=23, minute=59, second=59, microsecond=999999)\n+\n+        start_utc = start_of_day_local.astimezone(ZoneInfo('UTC'))\n+        end_utc = end_of_day_local.astimezone(ZoneInfo('UTC'))\n+\n+        # Get sessions updated in this UTC range\n+        rows = db.execute(\"\"\"\n+            SELECT editor_state_json\n+            FROM user_sessions\n+            WHERE user_id = ?\n+              AND updated_at >= ?\n+              AND updated_at <= ?\n+            ORDER BY updated_at DESC\n+        \"\"\", (user_id, start_utc.isoformat(), end_utc.isoformat())).fetchall()\n+\n+        # Extract text from each session\n+        all_text = []\n+        for row in rows:\n+            try:\n+                state = json.loads(row['editor_state_json'])\n+                # @@@ Same logic as frontend: filter text cells, extract content\n+                text = '\\n\\n'.join(\n+                    cell['content']\n+                    for cell in state.get('cells', [])\n+                    if cell.get('type') == 'text' and cell.get('content', '').strip()\n+                )\n+                if text.strip():\n+                    all_text.append(text)\n+            except (json.JSONDecodeError, KeyError):\n+                continue\n+\n+        return '\\n\\n'.join(all_text)\n+    finally:\n+        db.close()\n+\n # ========== Daily Pictures ==========\n \n def save_daily_picture(user_id: int, date: str, image_base64: str, prompt: str = None, thumbnail_base64: str = None):"
    },
    {
      "sha": "c309b176e680c3ada20f2f1cd15c7ba2cdb95c5c",
      "filename": "backend/scheduler.py",
      "status": "added",
      "additions": 169,
      "deletions": 0,
      "changes": 169,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fscheduler.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fscheduler.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fscheduler.py?ref=73a3187a708e5a9282fc0de3904f2aec4ac5347b",
      "patch": "@@ -0,0 +1,169 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Timeline auto-generation scheduler for Ink & Memory.\n+\n+Generates daily timeline images for users at midnight (Beijing time by default).\n+Runs concurrently for all users with activity on the previous day.\n+\"\"\"\n+\n+import asyncio\n+from concurrent.futures import ThreadPoolExecutor, as_completed\n+from datetime import datetime, timedelta\n+from zoneinfo import ZoneInfo\n+import database\n+from server import generate_daily_picture\n+\n+\n+async def generate_for_user(user_id: int, text: str, date: str) -> dict:\n+    \"\"\"\n+    Generate timeline image for a single user (async wrapper).\n+\n+    Args:\n+        user_id: User ID\n+        text: Text content from user's sessions on that date\n+        date: Date string (YYYY-MM-DD)\n+\n+    Returns:\n+        dict with success status and metadata\n+    \"\"\"\n+    try:\n+        # @@@ Check if image already exists for this date (avoid duplicates)\n+        existing_pictures = database.get_daily_pictures(user_id, limit=1000)\n+        if any(p['date'] == date for p in existing_pictures):\n+            print(f\"â­ï¸  User {user_id}: Image already exists for {date}, skipping\")\n+            return {\"success\": True, \"skipped\": True, \"user_id\": user_id, \"date\": date}\n+\n+        # Call the existing PolyCLI session function (runs in thread pool)\n+        print(f\"ðŸŽ¨ User {user_id}: Generating image for {date} ({len(text)} chars)\")\n+        loop = asyncio.get_event_loop()\n+        result = await loop.run_in_executor(\n+            None,\n+            lambda: generate_daily_picture(text, user_id, target_date=date)\n+        )\n+\n+        if result and 'image_base64' in result:\n+            # Save to database with explicit date\n+            database.save_daily_picture(\n+                user_id=user_id,\n+                date=date,\n+                image_base64=result['image_base64'],\n+                thumbnail_base64=result.get('thumbnail_base64'),\n+                prompt=result.get('prompt')\n+            )\n+            print(f\"âœ… User {user_id}: Successfully generated and saved image for {date}\")\n+            return {\"success\": True, \"user_id\": user_id, \"date\": date}\n+        else:\n+            print(f\"âŒ User {user_id}: Generation failed - no image returned\")\n+            return {\"success\": False, \"error\": \"No image returned\", \"user_id\": user_id, \"date\": date}\n+\n+    except Exception as e:\n+        print(f\"âŒ User {user_id}: Error generating image for {date}: {e}\")\n+        return {\"success\": False, \"error\": str(e), \"user_id\": user_id, \"date\": date}\n+\n+\n+async def generate_timeline_images_for_date(target_date: str, timezone: str = 'Asia/Shanghai', max_concurrent: int = 5):\n+    \"\"\"\n+    Generate timeline images for all users with activity on target_date.\n+\n+    Args:\n+        target_date: Date string (YYYY-MM-DD) in local timezone\n+        timezone: Timezone name (default: Asia/Shanghai for Beijing)\n+        max_concurrent: Maximum concurrent generations (rate limiting)\n+\n+    Returns:\n+        dict with statistics: total, success, failed, skipped\n+    \"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"ðŸ“… Timeline Auto-Generation Started\")\n+    print(f\"   Date: {target_date} ({timezone})\")\n+    print(f\"   Max concurrent: {max_concurrent}\")\n+    print(f\"{'='*60}\\n\")\n+\n+    try:\n+        # Step 1: Get users with activity on this date\n+        user_ids = database.get_users_with_activity_on_date(target_date, timezone)\n+        print(f\"ðŸ“Š Found {len(user_ids)} users with activity on {target_date}\")\n+\n+        if not user_ids:\n+            print(\"â„¹ï¸  No users with activity, exiting\")\n+            return {\"total\": 0, \"success\": 0, \"failed\": 0, \"skipped\": 0}\n+\n+        # Step 2: Extract text for each user\n+        tasks = []\n+        for user_id in user_ids:\n+            try:\n+                text = database.extract_text_from_sessions_on_date(user_id, target_date, timezone)\n+                if text.strip():\n+                    # Create async task with semaphore for rate limiting\n+                    task = generate_for_user(user_id, text, target_date)\n+                    tasks.append(task)\n+                else:\n+                    print(f\"â­ï¸  User {user_id}: No text content, skipping\")\n+            except Exception as e:\n+                print(f\"âŒ User {user_id}: Error extracting text: {e}\")\n+                continue\n+\n+        print(f\"ðŸš€ Starting generation for {len(tasks)} users (batched: {max_concurrent} concurrent)\")\n+\n+        # Step 3: Run with rate limiting (semaphore)\n+        semaphore = asyncio.Semaphore(max_concurrent)\n+\n+        async def bounded_generate(task):\n+            async with semaphore:\n+                return await task\n+\n+        results = await asyncio.gather(*[bounded_generate(task) for task in tasks], return_exceptions=True)\n+\n+        # Step 4: Summarize results\n+        success_count = sum(1 for r in results if isinstance(r, dict) and r.get('success') and not r.get('skipped'))\n+        failed_count = sum(1 for r in results if isinstance(r, dict) and not r.get('success'))\n+        skipped_count = sum(1 for r in results if isinstance(r, dict) and r.get('skipped'))\n+        exception_count = sum(1 for r in results if isinstance(r, Exception))\n+\n+        print(f\"\\n{'='*60}\")\n+        print(f\"âœ… Timeline Auto-Generation Completed\")\n+        print(f\"   Total: {len(tasks)}\")\n+        print(f\"   Success: {success_count}\")\n+        print(f\"   Skipped: {skipped_count}\")\n+        print(f\"   Failed: {failed_count + exception_count}\")\n+        print(f\"{'='*60}\\n\")\n+\n+        return {\n+            \"total\": len(tasks),\n+            \"success\": success_count,\n+            \"failed\": failed_count + exception_count,\n+            \"skipped\": skipped_count\n+        }\n+\n+    except Exception as e:\n+        print(f\"âŒ Timeline auto-generation failed: {e}\")\n+        import traceback\n+        traceback.print_exc()\n+        return {\"total\": 0, \"success\": 0, \"failed\": 0, \"skipped\": 0, \"error\": str(e)}\n+\n+\n+def get_previous_day(timezone: str = 'Asia/Shanghai') -> str:\n+    \"\"\"\n+    Get previous day's date in YYYY-MM-DD format (local timezone).\n+\n+    Args:\n+        timezone: Timezone name\n+\n+    Returns:\n+        Date string in YYYY-MM-DD format\n+    \"\"\"\n+    tz = ZoneInfo(timezone)\n+    now = datetime.now(tz)\n+    yesterday = now - timedelta(days=1)\n+    return yesterday.strftime('%Y-%m-%d')\n+\n+\n+# @@@ Scheduler job function (called by APScheduler)\n+async def daily_generation_job(timezone: str = 'Asia/Shanghai'):\n+    \"\"\"\n+    Daily job to generate timeline images for yesterday.\n+\n+    Called at midnight in the specified timezone.\n+    \"\"\"\n+    target_date = get_previous_day(timezone)\n+    await generate_timeline_images_for_date(target_date, timezone)"
    },
    {
      "sha": "7593b3a140551d340733cd8f1347fed466272db7",
      "filename": "backend/server.py",
      "status": "modified",
      "additions": 91,
      "deletions": 3,
      "changes": 94,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fserver.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/73a3187a708e5a9282fc0de3904f2aec4ac5347b/backend%2Fserver.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fserver.py?ref=73a3187a708e5a9282fc0de3904f2aec4ac5347b",
      "patch": "@@ -1,6 +1,7 @@\n #!/usr/bin/env python3\n \"\"\"FastAPI-based voice analysis server with sync API support.\"\"\"\n \n+import asyncio\n import httpx\n from fastapi import FastAPI, HTTPException, Depends, Header\n from fastapi.middleware.cors import CORSMiddleware\n@@ -419,15 +420,28 @@ def analyze_patterns(all_notes: str, user_id: int):\n     description=\"Generate an artistic image based on user's daily notes\",\n     params={\n         \"all_notes\": {\"type\": \"str\"},\n-        \"user_id\": {\"type\": \"int\"}\n+        \"user_id\": {\"type\": \"int\"},\n+        \"target_date\": {\"type\": \"str\"}  # Optional: YYYY-MM-DD format\n     },\n     category=\"Creative\"\n )\n-def generate_daily_picture(all_notes: str, user_id: int):\n-    \"\"\"Generate an image based on the essence of user's daily notes.\"\"\"\n+def generate_daily_picture(all_notes: str, user_id: int, target_date: str = None):\n+    \"\"\"Generate an image based on the essence of user's daily notes.\n+\n+    Args:\n+        all_notes: Text content from user's notes\n+        user_id: User ID\n+        target_date: Optional date string (YYYY-MM-DD). If None, uses today.\n+    \"\"\"\n+    from datetime import datetime\n+\n+    if target_date is None:\n+        target_date = datetime.now().strftime('%Y-%m-%d')\n+\n     print(f\"\\n{'='*60}\")\n     print(f\"ðŸŽ¨ generate_daily_picture() called\")\n     print(f\"   Notes length: {len(all_notes)} chars\")\n+    print(f\"   Target date: {target_date}\")\n     print(f\"{'='*60}\\n\")\n \n     import requests\n@@ -654,6 +668,45 @@ def generate_daily_picture(all_notes: str, user_id: int):\n     allow_headers=[\"*\"],\n )\n \n+# ========== Timeline Auto-Generation Scheduler ==========\n+\n+from apscheduler.schedulers.asyncio import AsyncIOScheduler\n+import scheduler as timeline_scheduler\n+\n+# Create scheduler instance\n+timeline_gen_scheduler = AsyncIOScheduler()\n+\n+@app.on_event(\"startup\")\n+async def startup_scheduler():\n+    \"\"\"Start the timeline auto-generation scheduler on app startup.\"\"\"\n+    print(\"\\n\" + \"=\"*60)\n+    print(\"ðŸ“… Starting Timeline Auto-Generation Scheduler\")\n+    print(\"   Schedule: Daily at 00:00 (midnight, Asia/Shanghai timezone)\")\n+    print(\"   Generates timeline images for previous day\")\n+    print(\"=\"*60 + \"\\n\")\n+\n+    # @@@ asyncio.run() creates new event loop for scheduler thread\n+    timeline_gen_scheduler.add_job(\n+        lambda: asyncio.run(timeline_scheduler.daily_generation_job()),\n+        'cron',\n+        hour=0,\n+        minute=0,\n+        timezone='Asia/Shanghai',\n+        id='daily_timeline_generation',\n+        name='Generate timeline images for yesterday',\n+        replace_existing=True\n+    )\n+\n+    timeline_gen_scheduler.start()\n+    print(\"âœ… Scheduler started - next run at midnight (00:00 Asia/Shanghai)\\n\")\n+\n+@app.on_event(\"shutdown\")\n+async def shutdown_scheduler():\n+    \"\"\"Shutdown the scheduler gracefully.\"\"\"\n+    print(\"\\nðŸ“… Shutting down timeline scheduler...\")\n+    timeline_gen_scheduler.shutdown(wait=False)\n+    print(\"âœ… Scheduler shutdown complete\\n\")\n+\n # ========== Request/Response Models ==========\n \n class RegisterRequest(BaseModel):\n@@ -1193,6 +1246,41 @@ def get_default_voices():\n     \"\"\"Get default voice configurations\"\"\"\n     return config.VOICE_ARCHETYPES\n \n+@app.post(\"/api/admin/trigger-timeline-generation\")\n+async def trigger_timeline_generation(date: str = None, timezone: str = 'Asia/Shanghai'):\n+    \"\"\"\n+    Manually trigger timeline image generation for a specific date (testing/admin).\n+\n+    Args:\n+        date: Target date in YYYY-MM-DD format (defaults to yesterday)\n+        timezone: Timezone name (default: Asia/Shanghai)\n+\n+    Returns:\n+        Generation statistics: total, success, failed, skipped\n+    \"\"\"\n+    if date is None:\n+        date = timeline_scheduler.get_previous_day(timezone)\n+\n+    print(f\"ðŸ”§ Manual trigger: Generating timeline images for {date}\")\n+\n+    try:\n+        result = await timeline_scheduler.generate_timeline_images_for_date(date, timezone)\n+        return {\n+            \"success\": True,\n+            \"date\": date,\n+            \"timezone\": timezone,\n+            **result\n+        }\n+    except Exception as e:\n+        import traceback\n+        traceback.print_exc()\n+        return {\n+            \"success\": False,\n+            \"error\": str(e),\n+            \"date\": date,\n+            \"timezone\": timezone\n+        }\n+\n # ========== Deck & Voice Management ==========\n \n class DeckCreateRequest(BaseModel):"
    }
  ]
}