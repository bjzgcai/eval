{
  "sha": "3de0a0c2093156f0c420724dbca83831d96bc879",
  "node_id": "C_kwDOP2Zrm9oAKDNkZTBhMGMyMDkzMTU2ZjBjNDIwNzI0ZGJjYTgzODMxZDk2YmM4Nzk",
  "commit": {
    "author": {
      "name": "lexicalmathical",
      "email": "lexicalmathical@gmail.com",
      "date": "2025-11-02T05:27:50Z"
    },
    "committer": {
      "name": "lexicalmathical",
      "email": "lexicalmathical@gmail.com",
      "date": "2025-11-02T05:27:50Z"
    },
    "message": "Add authentication system and database storage\n\nBackend changes:\n- Add JWT authentication with bcrypt password hashing (auth.py)\n- Implement SQLite database with WAL mode (database.py)\n- Add auth endpoints: register, login, /api/me\n- Add storage endpoints: sessions, pictures, preferences, reports\n- Add localStorage ‚Üí database migration endpoint\n- Refactor server.py to use FastAPI with auth middleware\n- Add comprehensive API documentation (API.md)\n\nDatabase schema:\n- users: Email/password accounts\n- user_sessions: Editor states\n- daily_pictures: Generated images (solves localStorage quota!)\n- user_preferences: Voice configs, meta prompt, state config\n- analysis_reports: Echoes, traits, patterns\n- schema_version: Migration tracking\n\nTesting:\n- test_migration.py: Unit tests for migration logic\n- test_real_migration.py: E2E test with real user data (4.79 MB migrated)\n\nFrontend changes:\n- Update voiceApi.ts to use sync API (removed polling)\n\nDocumentation:\n- LOCALSTORAGE_AUDIT.md: Complete inventory of localStorage usage\n- MIGRATION_SUMMARY.md: Migration strategy and storage comparison\n- API.md: Full API reference\n\nAll tests passing with real user data!",
    "tree": {
      "sha": "c011ce1e14c0a048777aa6f9d72117662e71f96c",
      "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/git/trees/c011ce1e14c0a048777aa6f9d72117662e71f96c"
    },
    "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/git/commits/3de0a0c2093156f0c420724dbca83831d96bc879",
    "comment_count": 0,
    "verification": {
      "verified": false,
      "reason": "unsigned",
      "signature": null,
      "payload": null,
      "verified_at": null
    }
  },
  "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/3de0a0c2093156f0c420724dbca83831d96bc879",
  "html_url": "https://github.com/shuxueshuxue/ink-and-memory/commit/3de0a0c2093156f0c420724dbca83831d96bc879",
  "comments_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/3de0a0c2093156f0c420724dbca83831d96bc879/comments",
  "author": null,
  "committer": null,
  "parents": [
    {
      "sha": "200a93c2aa475a059eb4bd07db346c1d0e05ec8e",
      "url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/commits/200a93c2aa475a059eb4bd07db346c1d0e05ec8e",
      "html_url": "https://github.com/shuxueshuxue/ink-and-memory/commit/200a93c2aa475a059eb4bd07db346c1d0e05ec8e"
    }
  ],
  "stats": {
    "total": 3392,
    "additions": 3177,
    "deletions": 215
  },
  "files": [
    {
      "sha": "74c3f9fc83f991603bf5a1d83dfe0f4e69e546b1",
      "filename": "backend/.gitignore",
      "status": "added",
      "additions": 1,
      "deletions": 0,
      "changes": 1,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2F.gitignore",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2F.gitignore",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2F.gitignore?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1 @@\n+test_data/"
    },
    {
      "sha": "77875334715261225bf2aedf80a73fd52b028ee0",
      "filename": "backend/API.md",
      "status": "added",
      "additions": 668,
      "deletions": 0,
      "changes": 668,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FAPI.md",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FAPI.md",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2FAPI.md?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,668 @@\n+# Ink & Memory API Documentation\n+\n+**Version:** 2.0.0\n+**Base URL:** `http://localhost:8765` (dev) | `https://lexicalmathical.com/ink-and-memory` (prod)\n+\n+## Authentication\n+\n+All endpoints except `/api/register`, `/api/login`, and `/api/default-voices` require authentication.\n+\n+**Header:** `Authorization: Bearer <JWT_TOKEN>`\n+\n+JWT tokens expire after 7 days.\n+\n+---\n+\n+## Auth Endpoints\n+\n+### POST `/api/register`\n+\n+Register a new user.\n+\n+**Request:**\n+```json\n+{\n+  \"email\": \"user@example.com\",\n+  \"password\": \"password123\",\n+  \"display_name\": \"Optional Name\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"token\": \"eyJhbGciOiJIUzI1...\",\n+  \"user\": {\n+    \"id\": 1,\n+    \"email\": \"user@example.com\",\n+    \"display_name\": \"Optional Name\"\n+  }\n+}\n+```\n+\n+**Errors:**\n+- `400` - Email/password missing or password < 6 chars\n+- `400` - Email already exists\n+\n+---\n+\n+### POST `/api/login`\n+\n+Login with email and password.\n+\n+**Request:**\n+```json\n+{\n+  \"email\": \"user@example.com\",\n+  \"password\": \"password123\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"token\": \"eyJhbGciOiJIUzI1...\",\n+  \"user\": {\n+    \"id\": 1,\n+    \"email\": \"user@example.com\",\n+    \"display_name\": \"Optional Name\"\n+  }\n+}\n+```\n+\n+**Errors:**\n+- `401` - Invalid email or password\n+\n+---\n+\n+### GET `/api/me`\n+\n+Get current user info from token.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Response:**\n+```json\n+{\n+  \"id\": 1,\n+  \"email\": \"user@example.com\",\n+  \"display_name\": \"Optional Name\",\n+  \"created_at\": \"2025-11-02 05:20:53\"\n+}\n+```\n+\n+**Errors:**\n+- `401` - Missing or invalid token\n+- `404` - User not found\n+\n+---\n+\n+## Migration Endpoint\n+\n+### POST `/api/import-local-data`\n+\n+One-time import of localStorage data to database on first login.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Request:**\n+```json\n+{\n+  \"currentSession\": \"{\\\"cells\\\": [...]}\",\n+  \"calendarEntries\": \"{\\\"2025-11-01\\\": [...]}\",\n+  \"dailyPictures\": \"[{\\\"date\\\": \\\"2025-11-01\\\", \\\"base64\\\": \\\"...\\\"}]\",\n+  \"voiceCustomizations\": \"{\\\"Logic\\\": {...}}\",\n+  \"metaPrompt\": \"Be helpful\",\n+  \"stateConfig\": \"{\\\"states\\\": {...}}\",\n+  \"selectedState\": \"happy\",\n+  \"analysisReports\": \"[{\\\"type\\\": \\\"echoes\\\", \\\"data\\\": {...}}]\",\n+  \"oldDocument\": \"{\\\"document\\\": \\\"...\\\"}\"\n+}\n+```\n+\n+All fields are optional. Strings should be JSON-stringified.\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"imported\": {\n+    \"sessions\": 6,\n+    \"pictures\": 2,\n+    \"preferences\": 4,\n+    \"reports\": 3\n+  }\n+}\n+```\n+\n+**Errors:**\n+- `401` - Missing or invalid token\n+\n+---\n+\n+## Session Storage\n+\n+### POST `/api/sessions`\n+\n+Save or update a session.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Request:**\n+```json\n+{\n+  \"session_id\": \"my-session-123\",\n+  \"name\": \"My Session Name\",\n+  \"editor_state\": {\n+    \"cells\": [\n+      {\"type\": \"text\", \"content\": \"Hello world\"}\n+    ],\n+    \"commentors\": []\n+  }\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true\n+}\n+```\n+\n+---\n+\n+### GET `/api/sessions`\n+\n+List all sessions for current user (metadata only, no editor_state).\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Response:**\n+```json\n+{\n+  \"sessions\": [\n+    {\n+      \"id\": \"session-123\",\n+      \"name\": \"My Session\",\n+      \"created_at\": \"2025-11-02 05:22:41\",\n+      \"updated_at\": \"2025-11-02 05:22:41\"\n+    }\n+  ]\n+}\n+```\n+\n+---\n+\n+### GET `/api/sessions/{session_id}`\n+\n+Get a specific session including full editor_state.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Response:**\n+```json\n+{\n+  \"id\": \"session-123\",\n+  \"name\": \"My Session\",\n+  \"created_at\": \"2025-11-02 05:22:41\",\n+  \"updated_at\": \"2025-11-02 05:22:41\",\n+  \"editor_state\": {\n+    \"cells\": [...],\n+    \"commentors\": []\n+  }\n+}\n+```\n+\n+**Errors:**\n+- `404` - Session not found\n+\n+---\n+\n+### DELETE `/api/sessions/{session_id}`\n+\n+Delete a session.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true\n+}\n+```\n+\n+---\n+\n+## Pictures\n+\n+### GET `/api/pictures`\n+\n+Get recent daily pictures.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Query params:**\n+- `limit` (optional, default 30) - Max number of pictures\n+\n+**Response:**\n+```json\n+{\n+  \"pictures\": [\n+    {\n+      \"date\": \"2025-11-02\",\n+      \"image_base64\": \"iVBORw0KGgoAAAANSUhEUg...\",\n+      \"prompt\": \"A serene landscape...\",\n+      \"created_at\": \"2025-11-02 05:22:41\"\n+    }\n+  ]\n+}\n+```\n+\n+---\n+\n+### POST `/api/pictures`\n+\n+Save a daily picture.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Request:**\n+```json\n+{\n+  \"date\": \"2025-11-02\",\n+  \"image_base64\": \"iVBORw0KGgoAAAANSUhEUg...\",\n+  \"prompt\": \"A serene landscape...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true\n+}\n+```\n+\n+**Errors:**\n+- `400` - date or image_base64 missing\n+\n+---\n+\n+## Preferences\n+\n+### GET `/api/preferences`\n+\n+Get user preferences.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Response:**\n+```json\n+{\n+  \"voice_configs\": {\n+    \"Logic\": {\n+      \"name\": \"Logic\",\n+      \"tagline\": \"...\",\n+      \"icon\": \"brain\",\n+      \"color\": \"blue\",\n+      \"enabled\": true\n+    }\n+  },\n+  \"meta_prompt\": \"Be helpful\",\n+  \"state_config\": {\n+    \"states\": {\n+      \"happy\": {\"name\": \"Happy\", \"prompt\": \"...\"}\n+    }\n+  },\n+  \"selected_state\": \"happy\",\n+  \"updated_at\": \"2025-11-02 05:22:41\"\n+}\n+```\n+\n+Returns empty object `{}` if no preferences set.\n+\n+---\n+\n+### POST `/api/preferences`\n+\n+Save user preferences (partial updates supported).\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Request (any combination of fields):**\n+```json\n+{\n+  \"voice_configs\": {...},\n+  \"meta_prompt\": \"Be creative\",\n+  \"state_config\": {...},\n+  \"selected_state\": \"happy\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true\n+}\n+```\n+\n+---\n+\n+## Analysis Reports\n+\n+### GET `/api/reports`\n+\n+Get recent analysis reports.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Query params:**\n+- `limit` (optional, default 10) - Max number of reports\n+\n+**Response:**\n+```json\n+{\n+  \"reports\": [\n+    {\n+      \"id\": 1,\n+      \"report_type\": \"echoes\",\n+      \"report_data\": {\n+        \"echoes\": [...]\n+      },\n+      \"created_at\": \"2025-11-02 05:22:41\"\n+    }\n+  ]\n+}\n+```\n+\n+---\n+\n+### POST `/api/reports`\n+\n+Save an analysis report.\n+\n+**Headers:** `Authorization: Bearer <token>`\n+\n+**Request:**\n+```json\n+{\n+  \"report_type\": \"echoes\",\n+  \"report_data\": {\n+    \"echoes\": [\n+      {\"title\": \"...\", \"description\": \"...\", \"examples\": [...]}\n+    ]\n+  },\n+  \"all_notes_text\": \"All the user's notes combined...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true\n+}\n+```\n+\n+**Errors:**\n+- `400` - report_type or report_data missing\n+\n+---\n+\n+## Voice Analysis (PolyCLI)\n+\n+### POST `/api/analyze`\n+\n+Analyze text and return ONE new voice comment (sync API).\n+\n+**Request:**\n+```json\n+{\n+  \"text\": \"User's text to analyze\",\n+  \"session_id\": \"session-123\",\n+  \"voices\": {...},\n+  \"applied_comments\": [],\n+  \"meta_prompt\": \"\",\n+  \"state_prompt\": \"\",\n+  \"overlapped_phrases\": []\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"voices\": [\n+      {\n+        \"phrase\": \"exact phrase\",\n+        \"voice\": \"Logic\",\n+        \"comment\": \"What the voice says\",\n+        \"icon\": \"brain\",\n+        \"color\": \"blue\"\n+      }\n+    ],\n+    \"new_voices_added\": 1\n+  }\n+}\n+```\n+\n+---\n+\n+### POST `/api/chat`\n+\n+Chat with a voice persona (sync API).\n+\n+**Request:**\n+```json\n+{\n+  \"voice_name\": \"Logic\",\n+  \"voice_config\": {...},\n+  \"conversation_history\": [\n+    {\"role\": \"user\", \"content\": \"Hi\"},\n+    {\"role\": \"assistant\", \"content\": \"Hello\"}\n+  ],\n+  \"user_message\": \"What do you think?\",\n+  \"original_text\": \"User's writing context\",\n+  \"meta_prompt\": \"\",\n+  \"state_prompt\": \"\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"response\": \"Voice's response to the user\"\n+  }\n+}\n+```\n+\n+---\n+\n+### POST `/api/generate-image`\n+\n+Generate artistic image from notes (sync API, 60s timeout).\n+\n+**Request:**\n+```json\n+{\n+  \"all_notes\": \"All user's notes combined...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"image_base64\": \"iVBORw0KGgoAAAANSUhEUg...\",\n+    \"prompt\": \"Creative image description\"\n+  }\n+}\n+```\n+\n+---\n+\n+### POST `/api/analyze-echoes`\n+\n+Find recurring themes in notes (sync API).\n+\n+**Request:**\n+```json\n+{\n+  \"all_notes\": \"All user's notes combined...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"echoes\": [\n+      {\n+        \"title\": \"Theme title\",\n+        \"description\": \"Pattern description\",\n+        \"examples\": [\"quote1\", \"quote2\"]\n+      }\n+    ]\n+  }\n+}\n+```\n+\n+---\n+\n+### POST `/api/analyze-traits`\n+\n+Identify personality traits from notes (sync API).\n+\n+**Request:**\n+```json\n+{\n+  \"all_notes\": \"All user's notes combined...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"traits\": [\n+      {\n+        \"trait\": \"Curious\",\n+        \"strength\": 4,\n+        \"evidence\": \"Examples from text...\"\n+      }\n+    ]\n+  }\n+}\n+```\n+\n+---\n+\n+### POST `/api/analyze-patterns`\n+\n+Identify behavioral patterns from notes (sync API).\n+\n+**Request:**\n+```json\n+{\n+  \"all_notes\": \"All user's notes combined...\"\n+}\n+```\n+\n+**Response:**\n+```json\n+{\n+  \"success\": true,\n+  \"result\": {\n+    \"patterns\": [\n+      {\n+        \"pattern\": \"Pattern name\",\n+        \"description\": \"Pattern description\",\n+        \"frequency\": \"Often/Sometimes/Rarely\"\n+      }\n+    ]\n+  }\n+}\n+```\n+\n+---\n+\n+### GET `/api/default-voices`\n+\n+Get default voice configurations (no auth required).\n+\n+**Response:**\n+```json\n+{\n+  \"Logic\": {\n+    \"tagline\": \"Wield raw intellectual power...\",\n+    \"icon\": \"brain\",\n+    \"color\": \"blue\"\n+  },\n+  \"Rhetoric\": {...},\n+  ...\n+}\n+```\n+\n+---\n+\n+## Error Responses\n+\n+All errors follow this format:\n+\n+```json\n+{\n+  \"detail\": \"Error message\"\n+}\n+```\n+\n+Common status codes:\n+- `400` - Bad request (missing/invalid params)\n+- `401` - Unauthorized (missing/invalid token)\n+- `404` - Not found\n+- `500` - Internal server error\n+\n+---\n+\n+## Development\n+\n+**Start server:**\n+```bash\n+cd backend\n+source .venv/bin/activate\n+python server.py\n+```\n+\n+**Run tests:**\n+```bash\n+python test_migration.py           # Test migration logic\n+python test_real_migration.py      # Test with real data\n+```\n+\n+**API Docs:**\n+- Interactive docs: http://localhost:8765/docs\n+- PolyCLI control panel: http://localhost:8765/polycli\n+\n+---\n+\n+## Database\n+\n+SQLite database at `backend/data/ink-and-memory.db`\n+\n+**Initialize/reset:**\n+```python\n+from database import init_db\n+init_db()\n+```\n+\n+**Tables:**\n+- `users` - User accounts\n+- `user_sessions` - Editor sessions\n+- `daily_pictures` - Generated images\n+- `user_preferences` - User settings\n+- `analysis_reports` - Analysis results\n+- `auth_sessions` - Session tokens (optional)\n+- `schema_version` - Migration tracking"
    },
    {
      "sha": "c2a6b0c9e1c80e2564766e0b1df5db03e2cd1c5c",
      "filename": "backend/LOCALSTORAGE_AUDIT.md",
      "status": "added",
      "additions": 157,
      "deletions": 0,
      "changes": 157,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FLOCALSTORAGE_AUDIT.md",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FLOCALSTORAGE_AUDIT.md",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2FLOCALSTORAGE_AUDIT.md?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,157 @@\n+# localStorage Audit - Complete Data Inventory\n+\n+## All localStorage Keys Currently Used\n+\n+### 1. **Editor State** (CRITICAL)\n+- **Key**: `ink_memory_state`\n+- **Location**: `App.tsx`\n+- **Content**: Full EditorState (cells, commentors, current session)\n+- **Size**: ~50-200KB per session\n+- **Migration**: ‚úÖ Save to `user_sessions` table\n+\n+### 2. **Calendar Entries** (CRITICAL)\n+- **Key**: `calendar-entries`\n+- **Location**: `calendarStorage.ts`\n+- **Content**: `{ \"YYYY-MM-DD\": [{ id, timestamp, state, firstLine }] }`\n+- **Size**: Can be LARGE (multiple full EditorStates)\n+- **Migration**: ‚úÖ Extract each entry and save as separate session in `user_sessions`\n+\n+### 3. **Daily Pictures** (CRITICAL - QUOTA PROBLEM!)\n+- **Key**: `daily-pictures`\n+- **Location**: `CollectionsView.tsx`\n+- **Content**: `[{ date, base64, prompt }]`\n+- **Size**: **1.5MB per image** ‚Üê This is why we need database!\n+- **Migration**: ‚úÖ Save to `daily_pictures` table\n+\n+### 4. **Voice Customizations**\n+- **Key**: `voice-customizations`\n+- **Location**: `voiceStorage.ts`\n+- **Content**: `{ [voiceKey]: { name, tagline, icon, color, enabled } }`\n+- **Size**: ~5-20KB\n+- **Migration**: ‚úÖ Save to `user_preferences.voice_configs_json`\n+\n+### 5. **Meta Prompt**\n+- **Key**: `meta-prompt`\n+- **Location**: `voiceStorage.ts`\n+- **Content**: String (global instructions for all voices)\n+- **Size**: ~1-5KB\n+- **Migration**: ‚úÖ Save to `user_preferences.meta_prompt`\n+\n+### 6. **State Config**\n+- **Key**: `state-config`\n+- **Location**: `voiceStorage.ts`\n+- **Content**: `{ greeting, states: { happy: {name, prompt}, ... } }`\n+- **Size**: ~2-10KB\n+- **Migration**: ‚úÖ Save to `user_preferences.state_config_json`\n+\n+### 7. **Selected State**\n+- **Key**: `selected-state`\n+- **Location**: `App.tsx`\n+- **Content**: String (e.g., \"happy\", \"ok\", \"unhappy\")\n+- **Size**: ~10 bytes\n+- **Migration**: ‚úÖ Save to `user_preferences.selected_state`\n+\n+### 8. **Analysis Reports History**\n+- **Key**: `analysis-reports-history`\n+- **Location**: `AnalysisView.tsx`\n+- **Content**: `[{ timestamp, type, data, allNotes }]`\n+- **Size**: ~10-50KB (limited to 10 reports)\n+- **Migration**: ‚ö†Ô∏è **MISSING FROM DATABASE!** Need new table\n+\n+### 9. **Document Storage** (OLD SYSTEM - probably unused?)\n+- **Key**: `ink_and_memory_document`\n+- **Location**: `documentStorage.ts`\n+- **Content**: `{ document, conversations, lastModified }`\n+- **Size**: Unknown\n+- **Migration**: ‚ö†Ô∏è **Check if this is still used** - might be deprecated\n+\n+## Database Schema Gaps Found\n+\n+### ‚ùå Missing Table: `analysis_reports`\n+```sql\n+CREATE TABLE analysis_reports (\n+  id INTEGER PRIMARY KEY AUTOINCREMENT,\n+  user_id INTEGER NOT NULL,\n+  report_type TEXT NOT NULL,  -- 'echoes', 'traits', 'patterns'\n+  report_data_json TEXT NOT NULL,\n+  all_notes_text TEXT,  -- The text that was analyzed\n+  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+  FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n+);\n+```\n+\n+### ‚ùå Missing: Calendar Entry Handling\n+- Calendar entries contain full EditorStates\n+- Need to extract each calendar entry as a separate session\n+- Need to preserve `date` and `timestamp` metadata\n+\n+## Migration Strategy\n+\n+### Phase 1: On First Login (Auto-Migration)\n+```javascript\n+async function migrateLocalStorageToServer() {\n+  const migrationData = {\n+    // Current session\n+    currentSession: localStorage.getItem('ink_memory_state'),\n+\n+    // Calendar entries (extract as separate sessions)\n+    calendarEntries: localStorage.getItem('calendar-entries'),\n+\n+    // Pictures (THE BIG ONE!)\n+    dailyPictures: localStorage.getItem('daily-pictures'),\n+\n+    // Preferences\n+    voiceCustomizations: localStorage.getItem('voice-customizations'),\n+    metaPrompt: localStorage.getItem('meta-prompt'),\n+    stateConfig: localStorage.getItem('state-config'),\n+    selectedState: localStorage.getItem('selected-state'),\n+\n+    // Reports\n+    analysisReports: localStorage.getItem('analysis-reports-history'),\n+\n+    // Old document storage (check if used)\n+    oldDocument: localStorage.getItem('ink_and_memory_document')\n+  };\n+\n+  // POST to /api/import-local-data\n+  await fetch('/api/import-local-data', {\n+    method: 'POST',\n+    headers: { 'Authorization': `Bearer ${token}` },\n+    body: JSON.stringify(migrationData)\n+  });\n+\n+  // Clear localStorage (keep only auth token)\n+  clearLocalStorage();\n+}\n+```\n+\n+### Phase 2: Server-First Operation\n+After migration:\n+- localStorage only stores: auth token\n+- All data fetched from server on load\n+- Auto-save to server every 30s\n+\n+## Size Estimates\n+\n+**Typical user localStorage usage:**\n+- Current session: ~100KB\n+- Calendar entries (30 days): ~3MB (30 sessions √ó 100KB)\n+- Daily pictures (7 days): **10.5MB** ‚Üê EXCEEDS QUOTA!\n+- Preferences: ~30KB\n+- Reports: ~50KB\n+- **TOTAL: ~13.7MB** ‚Üê Way over 5-10MB limit!\n+\n+**With database:**\n+- localStorage: ~1KB (just token)\n+- SQLite: Unlimited (file-based)\n+\n+## Action Items\n+\n+1. ‚úÖ Add `analysis_reports` table to database schema\n+2. ‚úÖ Update `import_user_data()` to handle:\n+   - Calendar entries extraction\n+   - Analysis reports\n+   - Old document storage check\n+3. ‚úÖ Create comprehensive migration endpoint `/api/import-local-data`\n+4. ‚ö†Ô∏è Test migration with real localStorage data\n+5. ‚ö†Ô∏è Add data validation (check JSON parsing before import)"
    },
    {
      "sha": "c8505d32179375ff1ca5c64f22adbb1ab4c3102d",
      "filename": "backend/MIGRATION_SUMMARY.md",
      "status": "added",
      "additions": 216,
      "deletions": 0,
      "changes": 216,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FMIGRATION_SUMMARY.md",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2FMIGRATION_SUMMARY.md",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2FMIGRATION_SUMMARY.md?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,216 @@\n+# localStorage Migration - Complete Picture\n+\n+## üö® Critical Discovery\n+\n+**Current localStorage usage: ~13.7MB per typical user**\n+- localStorage limit: 5-10MB\n+- **You've been living on borrowed time!**\n+\n+### The Quota Bomb:\n+```\n+Current session:      100 KB\n+Calendar (30 days):  3000 KB  (30 sessions)\n+Pictures (7 days):  10500 KB  ‚Üê THE PROBLEM!\n+Preferences:           30 KB\n+Reports:               50 KB\n+‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n+TOTAL:             ~13680 KB  ‚Üê 13.7 MB!\n+```\n+\n+**This explains the QuotaExceededError!**\n+\n+---\n+\n+## ‚úÖ Complete Data Inventory\n+\n+### 9 localStorage Keys Found:\n+\n+1. ‚úÖ `ink_memory_state` ‚Üí `user_sessions` table\n+2. ‚úÖ `calendar-entries` ‚Üí Extract each entry as separate session\n+3. ‚úÖ `daily-pictures` ‚Üí `daily_pictures` table\n+4. ‚úÖ `voice-customizations` ‚Üí `user_preferences.voice_configs_json`\n+5. ‚úÖ `meta-prompt` ‚Üí `user_preferences.meta_prompt`\n+6. ‚úÖ `state-config` ‚Üí `user_preferences.state_config_json`\n+7. ‚úÖ `selected-state` ‚Üí `user_preferences.selected_state`\n+8. ‚úÖ `analysis-reports-history` ‚Üí `analysis_reports` table (NEW!)\n+9. ‚ö†Ô∏è `ink_and_memory_document` ‚Üí Check if still used (might be old)\n+\n+---\n+\n+## üì¶ Database Schema (Complete)\n+\n+### Tables Created:\n+```sql\n+users                -- Email, password, display name\n+user_sessions        -- Editor states (replaces localStorage sessions)\n+daily_pictures       -- Images (solves quota problem!)\n+user_preferences     -- Voice configs, meta prompt, state config\n+analysis_reports     -- Echoes, traits, patterns (NEW!)\n+auth_sessions        -- Session tokens\n+schema_version       -- Migration tracking\n+```\n+\n+### Key Features:\n+- ‚úÖ WAL mode enabled (concurrent reads + 1 write)\n+- ‚úÖ Foreign keys enforced (CASCADE DELETE)\n+- ‚úÖ Indexes on user_id for fast queries\n+- ‚úÖ JSON columns for flexibility (no schema migrations needed)\n+\n+---\n+\n+## üîÑ Migration Plan\n+\n+### On First Login:\n+```javascript\n+// 1. Detect localStorage data\n+if (hasLocalStorageData()) {\n+  // 2. Show banner\n+  <Banner>\n+    üíæ Migrating your local data to your account...\n+  </Banner>\n+\n+  // 3. Extract all data\n+  const migrationData = extractAllLocalStorageData();\n+\n+  // 4. POST to server\n+  await fetch('/api/import-local-data', {\n+    method: 'POST',\n+    headers: { 'Authorization': `Bearer ${token}` },\n+    body: JSON.stringify(migrationData)\n+  });\n+\n+  // 5. Verify migration\n+  const verify = await fetch('/api/verify-migration');\n+\n+  // 6. Clear localStorage (keep only token)\n+  if (verify.ok) {\n+    clearLocalStorage();\n+    localStorage.setItem('auth-token', token);\n+  }\n+}\n+```\n+\n+### Special Cases:\n+\n+**Calendar Entries (Complex!):**\n+```javascript\n+// calendar-entries: { \"2025-11-01\": [entry1, entry2], \"2025-11-02\": [...] }\n+// Each entry contains full EditorState\n+\n+function extractCalendarEntries(calendarData) {\n+  const sessions = [];\n+\n+  for (const [date, entries] of Object.entries(calendarData)) {\n+    for (const entry of entries) {\n+      sessions.push({\n+        id: entry.id,\n+        name: `${date} - ${entry.firstLine}`,\n+        editor_state: entry.state,\n+        // Preserve original timestamp\n+        created_at: new Date(entry.timestamp).toISOString()\n+      });\n+    }\n+  }\n+\n+  return sessions;\n+}\n+```\n+\n+**Pictures (The Big One!):**\n+```javascript\n+// pictures: [{ date, base64, prompt }]\n+// Each base64 string is ~1.5MB!\n+\n+function extractPictures(picturesData) {\n+  return picturesData.map(p => ({\n+    date: p.date,\n+    image_base64: p.base64,  // Goes straight to SQLite (unlimited)\n+    prompt: p.prompt\n+  }));\n+}\n+```\n+\n+---\n+\n+## üéØ Guest Mode Strategy\n+\n+### Before Login:\n+```javascript\n+// localStorage works normally\n+localStorage.setItem('ink_memory_state', state);\n+localStorage.setItem('daily-pictures', pictures);\n+\n+// ‚ùå But blocks image generation if >5MB used\n+if (getLocalStorageSize() > 5 * 1024 * 1024) {\n+  alert('‚ö†Ô∏è Storage full! Create account to generate images.');\n+  return;\n+}\n+```\n+\n+### After Login:\n+```javascript\n+// Server becomes primary\n+await fetch('/api/save-session', { body: state });\n+\n+// localStorage only stores token\n+localStorage.clear();\n+localStorage.setItem('auth-token', token);\n+```\n+\n+### Image Generation Gate:\n+```javascript\n+async function generateImage() {\n+  if (!isLoggedIn()) {\n+    showLoginPrompt('üé® Create a free account to generate images');\n+    return;\n+  }\n+\n+  // Logged in users: unlimited images!\n+  const image = await fetch('/api/generate-image', ...);\n+}\n+```\n+\n+---\n+\n+## üìä Storage Comparison\n+\n+### Before (localStorage):\n+- Max: 10MB (hard limit)\n+- Current usage: ~13.7MB (OVER LIMIT!)\n+- Pictures: 7 max before quota error\n+- Sync: None (single device only)\n+- Backup: None (data lost if browser cache cleared)\n+\n+### After (SQLite):\n+- Max: Unlimited (file-based)\n+- Current usage: Irrelevant\n+- Pictures: Unlimited\n+- Sync: Across devices\n+- Backup: Daily automated backups\n+\n+---\n+\n+## üöÄ Next Steps\n+\n+1. [x] Database schema complete\n+2. [x] Migration functions ready\n+3. [ ] Create auth module (JWT, bcrypt)\n+4. [ ] Add auth endpoints to FastAPI\n+5. [ ] Create frontend login/register UI\n+6. [ ] Implement auto-migration on first login\n+7. [ ] Add image generation gate\n+8. [ ] Test with real localStorage data\n+9. [ ] Deploy to production\n+\n+---\n+\n+## ‚ö†Ô∏è Important Notes\n+\n+1. **No data loss**: Migration keeps localStorage until verified\n+2. **Rollback safe**: Can revert to localStorage if migration fails\n+3. **Incremental**: Users can keep using app during migration\n+4. **Guest mode works**: Anonymous users can still use app (limited)\n+\n+---\n+\n+**Ready to proceed with auth implementation!**"
    },
    {
      "sha": "cd6b50f7500fe011f90820c60a8af7485f499927",
      "filename": "backend/auth.py",
      "status": "added",
      "additions": 96,
      "deletions": 0,
      "changes": 96,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fauth.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fauth.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fauth.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,96 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Authentication module for Ink & Memory.\n+\n+Provides JWT token generation/verification and password hashing.\n+\"\"\"\n+\n+import jwt\n+import bcrypt\n+from datetime import datetime, timedelta\n+from typing import Optional\n+import os\n+\n+# @@@ JWT Configuration\n+SECRET_KEY = os.environ.get(\"JWT_SECRET_KEY\", \"dev-secret-change-in-production-123456789\")\n+ALGORITHM = \"HS256\"\n+ACCESS_TOKEN_EXPIRE_MINUTES = 60 * 24 * 7  # 7 days\n+\n+def hash_password(password: str) -> str:\n+    \"\"\"Hash a password using bcrypt.\"\"\"\n+    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')\n+\n+def verify_password(password: str, password_hash: str) -> bool:\n+    \"\"\"Verify a password against its hash.\"\"\"\n+    return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))\n+\n+def create_access_token(user_id: int, email: str) -> str:\n+    \"\"\"\n+    Create JWT access token.\n+\n+    Args:\n+        user_id: User ID\n+        email: User email\n+\n+    Returns:\n+        JWT token string\n+    \"\"\"\n+    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\n+\n+    payload = {\n+        \"sub\": str(user_id),  # Subject: user ID\n+        \"email\": email,\n+        \"exp\": expire,  # Expiration time\n+        \"iat\": datetime.utcnow()  # Issued at\n+    }\n+\n+    token = jwt.encode(payload, SECRET_KEY, algorithm=ALGORITHM)\n+    return token\n+\n+def verify_access_token(token: str) -> Optional[dict]:\n+    \"\"\"\n+    Verify JWT token and extract payload.\n+\n+    Args:\n+        token: JWT token string\n+\n+    Returns:\n+        Payload dict with user_id and email, or None if invalid\n+    \"\"\"\n+    try:\n+        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n+        user_id = int(payload.get(\"sub\"))\n+        email = payload.get(\"email\")\n+\n+        if user_id is None or email is None:\n+            return None\n+\n+        return {\n+            \"user_id\": user_id,\n+            \"email\": email\n+        }\n+    except jwt.ExpiredSignatureError:\n+        print(\"Token expired\")\n+        return None\n+    except jwt.InvalidTokenError:\n+        print(\"Invalid token\")\n+        return None\n+\n+def extract_token_from_header(authorization: Optional[str]) -> Optional[str]:\n+    \"\"\"\n+    Extract JWT token from Authorization header.\n+\n+    Args:\n+        authorization: Authorization header value (e.g., \"Bearer <token>\")\n+\n+    Returns:\n+        Token string or None\n+    \"\"\"\n+    if not authorization:\n+        return None\n+\n+    parts = authorization.split()\n+    if len(parts) != 2 or parts[0].lower() != \"bearer\":\n+        return None\n+\n+    return parts[1]"
    },
    {
      "sha": "481802f2ebabc08fd421d34342d42631f8838c66",
      "filename": "backend/data/ink-and-memory.db",
      "status": "added",
      "additions": 0,
      "deletions": 0,
      "changes": 0,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fdata%2Fink-and-memory.db",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fdata%2Fink-and-memory.db",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fdata%2Fink-and-memory.db?ref=3de0a0c2093156f0c420724dbca83831d96bc879"
    },
    {
      "sha": "2052cc42045fecc16646f41337012fce75ec139a",
      "filename": "backend/database.py",
      "status": "added",
      "additions": 446,
      "deletions": 0,
      "changes": 446,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fdatabase.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fdatabase.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fdatabase.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,446 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+SQLite database setup and migrations for Ink & Memory.\n+\n+Schema:\n+- users: User accounts (email, password_hash)\n+- user_sessions: Editor sessions (editor state JSON)\n+- daily_pictures: Generated images (base64)\n+- user_preferences: Voice configs, meta prompts, etc.\n+\"\"\"\n+\n+import sqlite3\n+import os\n+from pathlib import Path\n+from datetime import datetime, timedelta\n+import json\n+\n+# Database location\n+DB_DIR = Path(__file__).parent / \"data\"\n+DB_PATH = DB_DIR / \"ink-and-memory.db\"\n+\n+# Ensure data directory exists\n+DB_DIR.mkdir(exist_ok=True)\n+\n+def get_db():\n+    \"\"\"Get database connection with WAL mode enabled.\"\"\"\n+    db = sqlite3.connect(DB_PATH)\n+    db.row_factory = sqlite3.Row  # Access columns by name\n+\n+    # @@@ Enable WAL mode for concurrent reads + 1 write\n+    db.execute(\"PRAGMA journal_mode=WAL\")\n+    db.execute(\"PRAGMA foreign_keys=ON\")\n+\n+    return db\n+\n+def init_db():\n+    \"\"\"Initialize database with schema and migrations.\"\"\"\n+    db = get_db()\n+\n+    # Check current schema version\n+    try:\n+        result = db.execute(\"SELECT MAX(version) FROM schema_version\").fetchone()\n+        current_version = result[0] if result[0] else 0\n+    except sqlite3.OperationalError:\n+        # schema_version table doesn't exist yet\n+        current_version = 0\n+\n+    # Run migrations\n+    if current_version < 1:\n+        migrate_v1(db)\n+\n+    db.commit()\n+    db.close()\n+\n+    print(f\"‚úÖ Database initialized at {DB_PATH}\")\n+\n+def migrate_v1(db):\n+    \"\"\"Initial schema - users, sessions, pictures, preferences.\"\"\"\n+    print(\"üì¶ Running migration v1: Initial schema\")\n+\n+    # Schema version tracking\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS schema_version (\n+      version INTEGER PRIMARY KEY,\n+      applied_at DATETIME DEFAULT CURRENT_TIMESTAMP\n+    )\n+    \"\"\")\n+\n+    # Users table\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS users (\n+      id INTEGER PRIMARY KEY AUTOINCREMENT,\n+      email TEXT UNIQUE NOT NULL,\n+      password_hash TEXT NOT NULL,\n+      display_name TEXT,\n+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP\n+    )\n+    \"\"\")\n+\n+    # User sessions (editor states)\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS user_sessions (\n+      id TEXT PRIMARY KEY,\n+      user_id INTEGER NOT NULL,\n+      name TEXT,\n+      editor_state_json TEXT NOT NULL,\n+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n+    )\n+    \"\"\")\n+    db.execute(\"CREATE INDEX IF NOT EXISTS idx_sessions_user ON user_sessions(user_id)\")\n+\n+    # Daily pictures (generated images)\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS daily_pictures (\n+      id INTEGER PRIMARY KEY AUTOINCREMENT,\n+      user_id INTEGER NOT NULL,\n+      date TEXT NOT NULL,\n+      image_base64 TEXT NOT NULL,\n+      prompt TEXT,\n+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,\n+      UNIQUE(user_id, date)\n+    )\n+    \"\"\")\n+    db.execute(\"CREATE INDEX IF NOT EXISTS idx_pictures_user_date ON daily_pictures(user_id, date)\")\n+\n+    # User preferences (voice configs, meta prompts, etc.)\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS user_preferences (\n+      user_id INTEGER PRIMARY KEY,\n+      voice_configs_json TEXT,\n+      meta_prompt TEXT,\n+      state_config_json TEXT,\n+      selected_state TEXT,\n+      updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n+    )\n+    \"\"\")\n+\n+    # Auth sessions (JWT alternative - optional, using JWT for now)\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS auth_sessions (\n+      token TEXT PRIMARY KEY,\n+      user_id INTEGER NOT NULL,\n+      expires_at DATETIME NOT NULL,\n+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n+    )\n+    \"\"\")\n+    db.execute(\"CREATE INDEX IF NOT EXISTS idx_auth_user ON auth_sessions(user_id)\")\n+\n+    # @@@ Analysis reports (echoes, traits, patterns)\n+    db.execute(\"\"\"\n+    CREATE TABLE IF NOT EXISTS analysis_reports (\n+      id INTEGER PRIMARY KEY AUTOINCREMENT,\n+      user_id INTEGER NOT NULL,\n+      report_type TEXT NOT NULL,\n+      report_data_json TEXT NOT NULL,\n+      all_notes_text TEXT,\n+      created_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n+      FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE\n+    )\n+    \"\"\")\n+    db.execute(\"CREATE INDEX IF NOT EXISTS idx_reports_user ON analysis_reports(user_id, created_at)\")\n+\n+    # Record migration\n+    db.execute(\"INSERT INTO schema_version (version) VALUES (1)\")\n+\n+    print(\"‚úÖ Migration v1 completed\")\n+\n+# ========== User Management ==========\n+\n+def create_user(email: str, password_hash: str, display_name: str = None) -> int:\n+    \"\"\"Create a new user. Returns user_id.\"\"\"\n+    db = get_db()\n+    try:\n+        cursor = db.execute(\n+            \"INSERT INTO users (email, password_hash, display_name) VALUES (?, ?, ?)\",\n+            (email, password_hash, display_name)\n+        )\n+        user_id = cursor.lastrowid\n+        db.commit()\n+        return user_id\n+    except sqlite3.IntegrityError:\n+        raise ValueError(\"Email already exists\")\n+    finally:\n+        db.close()\n+\n+def get_user_by_email(email: str):\n+    \"\"\"Get user by email. Returns dict or None.\"\"\"\n+    db = get_db()\n+    try:\n+        row = db.execute(\n+            \"SELECT id, email, password_hash, display_name, created_at FROM users WHERE email = ?\",\n+            (email,)\n+        ).fetchone()\n+        return dict(row) if row else None\n+    finally:\n+        db.close()\n+\n+def get_user_by_id(user_id: int):\n+    \"\"\"Get user by ID. Returns dict or None.\"\"\"\n+    db = get_db()\n+    try:\n+        row = db.execute(\n+            \"SELECT id, email, display_name, created_at FROM users WHERE id = ?\",\n+            (user_id,)\n+        ).fetchone()\n+        return dict(row) if row else None\n+    finally:\n+        db.close()\n+\n+# ========== Session Storage ==========\n+\n+def save_session(user_id: int, session_id: str, editor_state: dict, name: str = None):\n+    \"\"\"Save or update a user session.\"\"\"\n+    db = get_db()\n+    try:\n+        db.execute(\"\"\"\n+        INSERT INTO user_sessions (id, user_id, name, editor_state_json, updated_at)\n+        VALUES (?, ?, ?, ?, CURRENT_TIMESTAMP)\n+        ON CONFLICT(id) DO UPDATE SET\n+          editor_state_json = excluded.editor_state_json,\n+          name = excluded.name,\n+          updated_at = CURRENT_TIMESTAMP\n+        \"\"\", (session_id, user_id, name, json.dumps(editor_state)))\n+        db.commit()\n+    finally:\n+        db.close()\n+\n+def get_session(user_id: int, session_id: str):\n+    \"\"\"Get a specific session. Returns dict or None.\"\"\"\n+    db = get_db()\n+    try:\n+        row = db.execute(\"\"\"\n+        SELECT id, name, editor_state_json, created_at, updated_at\n+        FROM user_sessions\n+        WHERE user_id = ? AND id = ?\n+        \"\"\", (user_id, session_id)).fetchone()\n+\n+        if row:\n+            result = dict(row)\n+            result['editor_state'] = json.loads(result['editor_state_json'])\n+            del result['editor_state_json']\n+            return result\n+        return None\n+    finally:\n+        db.close()\n+\n+def list_sessions(user_id: int):\n+    \"\"\"List all sessions for a user.\"\"\"\n+    db = get_db()\n+    try:\n+        rows = db.execute(\"\"\"\n+        SELECT id, name, created_at, updated_at\n+        FROM user_sessions\n+        WHERE user_id = ?\n+        ORDER BY updated_at DESC\n+        \"\"\", (user_id,)).fetchall()\n+        return [dict(row) for row in rows]\n+    finally:\n+        db.close()\n+\n+def delete_session(user_id: int, session_id: str):\n+    \"\"\"Delete a session.\"\"\"\n+    db = get_db()\n+    try:\n+        db.execute(\"DELETE FROM user_sessions WHERE user_id = ? AND id = ?\", (user_id, session_id))\n+        db.commit()\n+    finally:\n+        db.close()\n+\n+# ========== Daily Pictures ==========\n+\n+def save_daily_picture(user_id: int, date: str, image_base64: str, prompt: str = None):\n+    \"\"\"Save or update daily picture.\"\"\"\n+    db = get_db()\n+    try:\n+        db.execute(\"\"\"\n+        INSERT INTO daily_pictures (user_id, date, image_base64, prompt)\n+        VALUES (?, ?, ?, ?)\n+        ON CONFLICT(user_id, date) DO UPDATE SET\n+          image_base64 = excluded.image_base64,\n+          prompt = excluded.prompt\n+        \"\"\", (user_id, date, image_base64, prompt))\n+        db.commit()\n+    finally:\n+        db.close()\n+\n+def get_daily_pictures(user_id: int, limit: int = 30):\n+    \"\"\"Get recent daily pictures.\"\"\"\n+    db = get_db()\n+    try:\n+        rows = db.execute(\"\"\"\n+        SELECT date, image_base64, prompt, created_at\n+        FROM daily_pictures\n+        WHERE user_id = ?\n+        ORDER BY date DESC\n+        LIMIT ?\n+        \"\"\", (user_id, limit)).fetchall()\n+        return [dict(row) for row in rows]\n+    finally:\n+        db.close()\n+\n+# ========== User Preferences ==========\n+\n+def save_preferences(user_id: int, voice_configs: dict = None, meta_prompt: str = None,\n+                    state_config: dict = None, selected_state: str = None):\n+    \"\"\"Save or update user preferences.\"\"\"\n+    db = get_db()\n+    try:\n+        # Check if preferences exist\n+        existing = db.execute(\"SELECT user_id FROM user_preferences WHERE user_id = ?\", (user_id,)).fetchone()\n+\n+        if existing:\n+            # Update\n+            updates = []\n+            params = []\n+            if voice_configs is not None:\n+                updates.append(\"voice_configs_json = ?\")\n+                params.append(json.dumps(voice_configs))\n+            if meta_prompt is not None:\n+                updates.append(\"meta_prompt = ?\")\n+                params.append(meta_prompt)\n+            if state_config is not None:\n+                updates.append(\"state_config_json = ?\")\n+                params.append(json.dumps(state_config))\n+            if selected_state is not None:\n+                updates.append(\"selected_state = ?\")\n+                params.append(selected_state)\n+\n+            if updates:\n+                updates.append(\"updated_at = CURRENT_TIMESTAMP\")\n+                params.append(user_id)\n+                db.execute(f\"UPDATE user_preferences SET {', '.join(updates)} WHERE user_id = ?\", params)\n+        else:\n+            # Insert\n+            db.execute(\"\"\"\n+            INSERT INTO user_preferences (user_id, voice_configs_json, meta_prompt, state_config_json, selected_state)\n+            VALUES (?, ?, ?, ?, ?)\n+            \"\"\", (user_id,\n+                  json.dumps(voice_configs) if voice_configs else None,\n+                  meta_prompt,\n+                  json.dumps(state_config) if state_config else None,\n+                  selected_state))\n+\n+        db.commit()\n+    finally:\n+        db.close()\n+\n+def get_preferences(user_id: int):\n+    \"\"\"Get user preferences. Returns dict or None.\"\"\"\n+    db = get_db()\n+    try:\n+        row = db.execute(\"\"\"\n+        SELECT voice_configs_json, meta_prompt, state_config_json, selected_state, updated_at\n+        FROM user_preferences\n+        WHERE user_id = ?\n+        \"\"\", (user_id,)).fetchone()\n+\n+        if row:\n+            result = dict(row)\n+            result['voice_configs'] = json.loads(result['voice_configs_json']) if result['voice_configs_json'] else None\n+            result['state_config'] = json.loads(result['state_config_json']) if result['state_config_json'] else None\n+            del result['voice_configs_json']\n+            del result['state_config_json']\n+            return result\n+        return None\n+    finally:\n+        db.close()\n+\n+# ========== Analysis Reports ==========\n+\n+def save_analysis_report(user_id: int, report_type: str, report_data: dict, all_notes_text: str = None):\n+    \"\"\"Save an analysis report.\"\"\"\n+    db = get_db()\n+    try:\n+        db.execute(\"\"\"\n+        INSERT INTO analysis_reports (user_id, report_type, report_data_json, all_notes_text)\n+        VALUES (?, ?, ?, ?)\n+        \"\"\", (user_id, report_type, json.dumps(report_data), all_notes_text))\n+        db.commit()\n+    finally:\n+        db.close()\n+\n+def get_analysis_reports(user_id: int, limit: int = 10):\n+    \"\"\"Get recent analysis reports.\"\"\"\n+    db = get_db()\n+    try:\n+        rows = db.execute(\"\"\"\n+        SELECT id, report_type, report_data_json, created_at\n+        FROM analysis_reports\n+        WHERE user_id = ?\n+        ORDER BY created_at DESC\n+        LIMIT ?\n+        \"\"\", (user_id, limit)).fetchall()\n+\n+        results = []\n+        for row in rows:\n+            result = dict(row)\n+            result['report_data'] = json.loads(result['report_data_json'])\n+            del result['report_data_json']\n+            results.append(result)\n+        return results\n+    finally:\n+        db.close()\n+\n+# ========== Bulk Import (for localStorage migration) ==========\n+\n+def import_user_data(user_id: int, sessions: list, pictures: list, preferences: dict, reports: list = None):\n+    \"\"\"\n+    Bulk import user data from localStorage migration.\n+\n+    Args:\n+        user_id: User ID\n+        sessions: List of {id, name, editor_state}\n+        pictures: List of {date, image_base64, prompt}\n+        preferences: {voice_configs, meta_prompt, state_config, selected_state}\n+        reports: Optional list of {type, data, allNotes, timestamp}\n+    \"\"\"\n+    db = get_db()\n+    try:\n+        # Import sessions\n+        for session in sessions:\n+            db.execute(\"\"\"\n+            INSERT OR REPLACE INTO user_sessions (id, user_id, name, editor_state_json)\n+            VALUES (?, ?, ?, ?)\n+            \"\"\", (session['id'], user_id, session.get('name'), json.dumps(session['editor_state'])))\n+\n+        # Import pictures\n+        for picture in pictures:\n+            db.execute(\"\"\"\n+            INSERT OR REPLACE INTO daily_pictures (user_id, date, image_base64, prompt)\n+            VALUES (?, ?, ?, ?)\n+            \"\"\", (user_id, picture['date'], picture['image_base64'], picture.get('prompt')))\n+\n+        # Import preferences\n+        if preferences:\n+            db.execute(\"\"\"\n+            INSERT OR REPLACE INTO user_preferences\n+            (user_id, voice_configs_json, meta_prompt, state_config_json, selected_state)\n+            VALUES (?, ?, ?, ?, ?)\n+            \"\"\", (user_id,\n+                  json.dumps(preferences.get('voice_configs')) if preferences.get('voice_configs') else None,\n+                  preferences.get('meta_prompt'),\n+                  json.dumps(preferences.get('state_config')) if preferences.get('state_config') else None,\n+                  preferences.get('selected_state')))\n+\n+        # Import analysis reports\n+        if reports:\n+            for report in reports:\n+                db.execute(\"\"\"\n+                INSERT INTO analysis_reports (user_id, report_type, report_data_json, all_notes_text)\n+                VALUES (?, ?, ?, ?)\n+                \"\"\", (user_id, report.get('type', 'unknown'), json.dumps(report.get('data', {})), report.get('allNotes')))\n+\n+        db.commit()\n+        print(f\"‚úÖ Imported {len(sessions)} sessions, {len(pictures)} pictures, {len(reports or [])} reports for user {user_id}\")\n+    finally:\n+        db.close()\n+\n+if __name__ == \"__main__\":\n+    # Initialize database\n+    init_db()"
    },
    {
      "sha": "abc67fcea36ec2029f959c0273d3eb0e74e770c5",
      "filename": "backend/server.py",
      "status": "modified",
      "additions": 604,
      "deletions": 79,
      "changes": 683,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fserver.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fserver.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fserver.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -1,12 +1,23 @@\n #!/usr/bin/env python3\n-\"\"\"Stateless voice analysis server - no state tracking, just returns new comments.\"\"\"\n+\"\"\"FastAPI-based voice analysis server with sync API support.\"\"\"\n \n-import time\n+import httpx\n+from fastapi import FastAPI, HTTPException, Depends, Header\n+from fastapi.middleware.cors import CORSMiddleware\n from polycli.orchestration.session_registry import session_def, get_registry\n+from polycli.integrations.fastapi import mount_control_panel\n from polycli import PolyAgent\n from stateless_analyzer import analyze_stateless\n import config\n from proxy_config import get_image_api_proxies\n+from typing import Optional\n+from pydantic import BaseModel\n+\n+# Import database and auth modules\n+import database\n+import auth\n+\n+# ========== Session Definitions (PolyCLI) ==========\n \n @session_def(\n     name=\"Chat with Voice\",\n@@ -23,20 +34,7 @@\n     category=\"Chat\"\n )\n def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: list, user_message: str, original_text: str = \"\", meta_prompt: str = \"\", state_prompt: str = \"\"):\n-    \"\"\"\n-    Chat with a specific voice persona.\n-\n-    Args:\n-        voice_name: Name of the voice (e.g., \"Logic\", \"Drama\")\n-        voice_config: Voice configuration with tagline, icon, color\n-        conversation_history: Previous messages in the conversation\n-        user_message: The user's new message\n-        original_text: The user's original writing text\n-        meta_prompt: Additional instructions that apply to all voices\n-\n-    Returns:\n-        Dictionary with assistant's response\n-    \"\"\"\n+    \"\"\"Chat with a specific voice persona.\"\"\"\n     print(f\"\\n{'='*60}\")\n     print(f\"üí¨ chat_with_voice() called\")\n     print(f\"   Voice: {voice_name}\")\n@@ -79,7 +77,7 @@ def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: l\n Additional instructions:\n {meta_prompt.strip()}\"\"\"\n \n-    # @@@ Add state prompt if available (between meta and voice-specific)\n+    # Add state prompt if available\n     if state_prompt and state_prompt.strip():\n         system_prompt += f\"\"\"\n \n@@ -126,21 +124,7 @@ def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: l\n     category=\"Analysis\"\n )\n def analyze_text(text: str, session_id: str, voices: dict = None, applied_comments: list = None, meta_prompt: str = \"\", state_prompt: str = \"\", overlapped_phrases: list = None):\n-    \"\"\"\n-    Stateless analysis - returns ONE new comment based on text and applied comments.\n-\n-    Args:\n-        text: Text to analyze (should be complete sentences only)\n-        session_id: Session ID (for future use)\n-        voices: Voice configuration\n-        applied_comments: List of already applied comments (to avoid duplicates)\n-        meta_prompt: Additional instructions that apply to all voices\n-        state_prompt: User's current emotional state prompt\n-        overlapped_phrases: Phrases that were rejected due to overlap (feedback loop)\n-\n-    Returns:\n-        Dictionary with single new voice (or empty list)\n-    \"\"\"\n+    \"\"\"Stateless analysis - returns ONE new comment based on text and applied comments.\"\"\"\n     print(f\"\\n{'='*60}\")\n     print(f\"üéØ Stateless analyze_text() called\")\n     print(f\"   Text: {text[:100]}...\")\n@@ -319,21 +303,15 @@ def analyze_patterns(all_notes: str):\n     category=\"Creative\"\n )\n def generate_daily_picture(all_notes: str):\n-    \"\"\"Generate an image based on the essence of user's daily notes.\n-\n-    Uses a two-step process:\n-    1. LLM analyzes notes and creates artistic image description\n-    2. Image generation model creates the image\n-    \"\"\"\n+    \"\"\"Generate an image based on the essence of user's daily notes.\"\"\"\n     print(f\"\\n{'='*60}\")\n     print(f\"üé® generate_daily_picture() called\")\n     print(f\"   Notes length: {len(all_notes)} chars\")\n     print(f\"{'='*60}\\n\")\n \n     import requests\n \n-    # @@@ Step 1: Convert notes to artistic image description using Claude Haiku\n-\n+    # Step 1: Convert notes to artistic image description using Claude Haiku\n     description_prompt = f\"\"\"Read these personal notes and create a vivid, artistic image description that captures the essence, mood, and themes.\n \n Notes:\n@@ -353,7 +331,7 @@ def generate_daily_picture(all_notes: str):\n \n     print(\"üß† Creating image description from notes with Claude Haiku...\")\n \n-    # @@@ Use proxy for GFW bypass (if configured)\n+    # Use proxy for GFW bypass (if configured)\n     proxies = get_image_api_proxies()\n \n     claude_response = requests.post(\n@@ -382,7 +360,7 @@ def generate_daily_picture(all_notes: str):\n \n     print(f\"üìù Image description: {image_description}\")\n \n-    # @@@ Step 2: Generate image from description with retry logic\n+    # Step 2: Generate image from description with retry logic\n     url = f\"{config.IMAGE_API_ENDPOINT}/chat/completions\"\n     headers = {\n         \"Authorization\": f\"Bearer {config.IMAGE_API_KEY}\",\n@@ -400,7 +378,7 @@ def generate_daily_picture(all_notes: str):\n         \"max_tokens\": config.IMAGE_MAX_TOKENS\n     }\n \n-    # @@@ Retry logic with increasing timeouts\n+    # Retry logic with increasing timeouts\n     for attempt in range(1, config.IMAGE_RETRY_MAX_ATTEMPTS + 1):\n         try:\n             timeout_seconds = config.IMAGE_RETRY_BASE_TIMEOUT + (attempt - 1) * config.IMAGE_RETRY_TIMEOUT_INCREMENT\n@@ -456,43 +434,590 @@ def generate_daily_picture(all_notes: str):\n \n     return {\"image_base64\": None, \"error\": \"All retry attempts failed\"}\n \n+# ========== FastAPI Application ==========\n+\n+app = FastAPI(\n+    title=\"Ink & Memory API\",\n+    description=\"Voice analysis and creative generation API\",\n+    version=\"2.0.0\"\n+)\n+\n+# Add CORS middleware\n+app.add_middleware(\n+    CORSMiddleware,\n+    allow_origins=[\"*\"],  # In production, restrict to specific origins\n+    allow_credentials=True,\n+    allow_methods=[\"*\"],\n+    allow_headers=[\"*\"],\n+)\n+\n+# ========== Request/Response Models ==========\n+\n+class RegisterRequest(BaseModel):\n+    email: str\n+    password: str\n+    display_name: Optional[str] = None\n+\n+class LoginRequest(BaseModel):\n+    email: str\n+    password: str\n+\n+class TokenResponse(BaseModel):\n+    token: str\n+    user: dict\n+\n+class ImportDataRequest(BaseModel):\n+    currentSession: Optional[str] = None\n+    calendarEntries: Optional[str] = None\n+    dailyPictures: Optional[str] = None\n+    voiceCustomizations: Optional[str] = None\n+    metaPrompt: Optional[str] = None\n+    stateConfig: Optional[str] = None\n+    selectedState: Optional[str] = None\n+    analysisReports: Optional[str] = None\n+    oldDocument: Optional[str] = None\n+\n+# ========== Auth Dependency ==========\n+\n+def get_current_user(authorization: Optional[str] = Header(None)) -> dict:\n+    \"\"\"\n+    Dependency to extract and verify JWT token from Authorization header.\n+\n+    Raises:\n+        HTTPException 401 if token is missing or invalid\n+    \"\"\"\n+    token = auth.extract_token_from_header(authorization)\n+    if not token:\n+        raise HTTPException(status_code=401, detail=\"Missing authorization token\")\n+\n+    user_data = auth.verify_access_token(token)\n+    if not user_data:\n+        raise HTTPException(status_code=401, detail=\"Invalid or expired token\")\n+\n+    return user_data\n+\n+# ========== Custom API Endpoints (Clean Interface) ==========\n+\n+@app.get(\"/\")\n+def root():\n+    \"\"\"Root endpoint\"\"\"\n+    return {\n+        \"service\": \"Ink & Memory API\",\n+        \"version\": \"2.0.0\",\n+        \"docs\": \"/docs\",\n+        \"control_panel\": \"/polycli\"\n+    }\n+\n+# ========== Auth Endpoints ==========\n+\n+@app.post(\"/api/register\", response_model=TokenResponse)\n+def register(request: RegisterRequest):\n+    \"\"\"\n+    Register a new user.\n+\n+    Returns JWT token and user info.\n+    \"\"\"\n+    # Validate input\n+    if not request.email or not request.password:\n+        raise HTTPException(status_code=400, detail=\"Email and password required\")\n+\n+    if len(request.password) < 6:\n+        raise HTTPException(status_code=400, detail=\"Password must be at least 6 characters\")\n+\n+    # Hash password\n+    password_hash = auth.hash_password(request.password)\n+\n+    # Create user\n+    try:\n+        user_id = database.create_user(request.email, password_hash, request.display_name)\n+    except ValueError as e:\n+        raise HTTPException(status_code=400, detail=str(e))\n+\n+    # Generate token\n+    token = auth.create_access_token(user_id, request.email)\n+\n+    return {\n+        \"token\": token,\n+        \"user\": {\n+            \"id\": user_id,\n+            \"email\": request.email,\n+            \"display_name\": request.display_name\n+        }\n+    }\n+\n+@app.post(\"/api/login\", response_model=TokenResponse)\n+def login(request: LoginRequest):\n+    \"\"\"\n+    Login with email and password.\n+\n+    Returns JWT token and user info.\n+    \"\"\"\n+    # Get user by email\n+    user = database.get_user_by_email(request.email)\n+    if not user:\n+        raise HTTPException(status_code=401, detail=\"Invalid email or password\")\n+\n+    # Verify password\n+    if not auth.verify_password(request.password, user['password_hash']):\n+        raise HTTPException(status_code=401, detail=\"Invalid email or password\")\n+\n+    # Generate token\n+    token = auth.create_access_token(user['id'], user['email'])\n+\n+    return {\n+        \"token\": token,\n+        \"user\": {\n+            \"id\": user['id'],\n+            \"email\": user['email'],\n+            \"display_name\": user['display_name']\n+        }\n+    }\n+\n+@app.get(\"/api/me\")\n+def get_current_user_info(current_user: dict = Depends(get_current_user)):\n+    \"\"\"\n+    Get current user info from token.\n+\n+    Requires Authorization header with Bearer token.\n+    \"\"\"\n+    user = database.get_user_by_id(current_user['user_id'])\n+    if not user:\n+        raise HTTPException(status_code=404, detail=\"User not found\")\n+\n+    return {\n+        \"id\": user['id'],\n+        \"email\": user['email'],\n+        \"display_name\": user['display_name'],\n+        \"created_at\": user['created_at']\n+    }\n+\n+@app.post(\"/api/import-local-data\")\n+def import_local_data(request: ImportDataRequest, current_user: dict = Depends(get_current_user)):\n+    \"\"\"\n+    Import localStorage data to database on first login.\n+\n+    Extracts sessions, pictures, preferences, and reports from localStorage export.\n+    \"\"\"\n+    import json\n+\n+    user_id = current_user['user_id']\n+\n+    # Extract sessions\n+    sessions = []\n+\n+    # 1. Current session\n+    if request.currentSession:\n+        try:\n+            current = json.loads(request.currentSession)\n+            sessions.append({\n+                'id': 'current-session',\n+                'name': 'Current Session',\n+                'editor_state': current\n+            })\n+        except:\n+            pass\n+\n+    # 2. Calendar entries\n+    if request.calendarEntries:\n+        try:\n+            calendar = json.loads(request.calendarEntries)\n+            for date, entries in calendar.items():\n+                for entry in entries:\n+                    sessions.append({\n+                        'id': entry['id'],\n+                        'name': f\"{date} - {entry.get('firstLine', 'Untitled')}\",\n+                        'editor_state': entry['state']\n+                    })\n+        except:\n+            pass\n+\n+    # 3. Old document (if exists)\n+    if request.oldDocument:\n+        try:\n+            old_doc = json.loads(request.oldDocument)\n+            if old_doc and old_doc.get('document'):\n+                sessions.append({\n+                    'id': 'old-document',\n+                    'name': 'Old Document (migrated)',\n+                    'editor_state': {'cells': [{'type': 'text', 'content': str(old_doc)}]}\n+                })\n+        except:\n+            pass\n+\n+    # Extract pictures\n+    pictures = []\n+    if request.dailyPictures:\n+        try:\n+            pics = json.loads(request.dailyPictures)\n+            for pic in pics:\n+                pictures.append({\n+                    'date': pic['date'],\n+                    'image_base64': pic['base64'],\n+                    'prompt': pic.get('prompt', '')\n+                })\n+        except:\n+            pass\n+\n+    # Extract preferences\n+    preferences = {}\n+    if request.voiceCustomizations:\n+        try:\n+            preferences['voice_configs'] = json.loads(request.voiceCustomizations)\n+        except:\n+            pass\n+\n+    if request.metaPrompt:\n+        preferences['meta_prompt'] = request.metaPrompt\n+\n+    if request.stateConfig:\n+        try:\n+            preferences['state_config'] = json.loads(request.stateConfig)\n+        except:\n+            pass\n+\n+    if request.selectedState:\n+        preferences['selected_state'] = request.selectedState\n+\n+    # Extract reports\n+    reports = []\n+    if request.analysisReports:\n+        try:\n+            report_list = json.loads(request.analysisReports)\n+            for report in report_list:\n+                reports.append({\n+                    'type': report.get('type', 'unknown'),\n+                    'data': report.get('data', {}),\n+                    'allNotes': report.get('allNotes', ''),\n+                    'timestamp': report.get('timestamp', '')\n+                })\n+        except:\n+            pass\n+\n+    # Import to database\n+    database.import_user_data(user_id, sessions, pictures, preferences, reports)\n+\n+    return {\n+        \"success\": True,\n+        \"imported\": {\n+            \"sessions\": len(sessions),\n+            \"pictures\": len(pictures),\n+            \"preferences\": len([k for k, v in preferences.items() if v]),\n+            \"reports\": len(reports)\n+        }\n+    }\n+\n+# ========== Session Storage Endpoints ==========\n+\n+@app.post(\"/api/sessions\")\n+def save_session(\n+    request: dict,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"\n+    Save or update a session.\n+\n+    Request body:\n+    {\n+        \"session_id\": \"string\",\n+        \"name\": \"optional string\",\n+        \"editor_state\": {...}\n+    }\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    session_id = request.get('session_id')\n+    editor_state = request.get('editor_state')\n+    name = request.get('name')\n+\n+    if not session_id or not editor_state:\n+        raise HTTPException(status_code=400, detail=\"session_id and editor_state required\")\n+\n+    database.save_session(user_id, session_id, editor_state, name)\n+\n+    return {\"success\": True}\n+\n+@app.get(\"/api/sessions\")\n+def list_sessions(current_user: dict = Depends(get_current_user)):\n+    \"\"\"\n+    List all sessions for current user.\n+\n+    Returns: Array of session metadata (without full editor state)\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    sessions = database.list_sessions(user_id)\n+    return {\"sessions\": sessions}\n+\n+@app.get(\"/api/sessions/{session_id}\")\n+def get_session(session_id: str, current_user: dict = Depends(get_current_user)):\n+    \"\"\"\n+    Get a specific session by ID.\n+\n+    Returns: Full session including editor_state\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    session = database.get_session(user_id, session_id)\n+\n+    if not session:\n+        raise HTTPException(status_code=404, detail=\"Session not found\")\n+\n+    return session\n+\n+@app.delete(\"/api/sessions/{session_id}\")\n+def delete_session_endpoint(session_id: str, current_user: dict = Depends(get_current_user)):\n+    \"\"\"Delete a session.\"\"\"\n+    user_id = current_user['user_id']\n+    database.delete_session(user_id, session_id)\n+    return {\"success\": True}\n+\n+# ========== Pictures Endpoints ==========\n+\n+@app.get(\"/api/pictures\")\n+def get_pictures(\n+    limit: int = 30,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"\n+    Get recent daily pictures for current user.\n+\n+    Query params:\n+    - limit: Max number of pictures to return (default 30)\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    pictures = database.get_daily_pictures(user_id, limit)\n+    return {\"pictures\": pictures}\n+\n+@app.post(\"/api/pictures\")\n+def save_picture(\n+    request: dict,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"\n+    Save a daily picture.\n+\n+    Request body:\n+    {\n+        \"date\": \"YYYY-MM-DD\",\n+        \"image_base64\": \"base64 string\",\n+        \"prompt\": \"optional prompt\"\n+    }\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    date = request.get('date')\n+    image_base64 = request.get('image_base64')\n+    prompt = request.get('prompt', '')\n+\n+    if not date or not image_base64:\n+        raise HTTPException(status_code=400, detail=\"date and image_base64 required\")\n+\n+    database.save_daily_picture(user_id, date, image_base64, prompt)\n+    return {\"success\": True}\n+\n+# ========== Preferences Endpoints ==========\n+\n+@app.get(\"/api/preferences\")\n+def get_preferences(current_user: dict = Depends(get_current_user)):\n+    \"\"\"Get user preferences.\"\"\"\n+    user_id = current_user['user_id']\n+    preferences = database.get_preferences(user_id)\n+    return preferences or {}\n+\n+@app.post(\"/api/preferences\")\n+def save_preferences_endpoint(\n+    request: dict,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"\n+    Save user preferences.\n+\n+    Request body can contain any of:\n+    - voice_configs: dict\n+    - meta_prompt: str\n+    - state_config: dict\n+    - selected_state: str\n+    \"\"\"\n+    user_id = current_user['user_id']\n+\n+    database.save_preferences(\n+        user_id,\n+        voice_configs=request.get('voice_configs'),\n+        meta_prompt=request.get('meta_prompt'),\n+        state_config=request.get('state_config'),\n+        selected_state=request.get('selected_state')\n+    )\n+\n+    return {\"success\": True}\n+\n+# ========== Analysis Reports Endpoints ==========\n+\n+@app.get(\"/api/reports\")\n+def get_reports(\n+    limit: int = 10,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"Get recent analysis reports.\"\"\"\n+    user_id = current_user['user_id']\n+    reports = database.get_analysis_reports(user_id, limit)\n+    return {\"reports\": reports}\n+\n+@app.post(\"/api/reports\")\n+def save_report(\n+    request: dict,\n+    current_user: dict = Depends(get_current_user)\n+):\n+    \"\"\"\n+    Save an analysis report.\n+\n+    Request body:\n+    {\n+        \"report_type\": \"echoes\" | \"traits\" | \"patterns\",\n+        \"report_data\": {...},\n+        \"all_notes_text\": \"optional text\"\n+    }\n+    \"\"\"\n+    user_id = current_user['user_id']\n+    report_type = request.get('report_type')\n+    report_data = request.get('report_data')\n+    all_notes_text = request.get('all_notes_text', '')\n+\n+    if not report_type or not report_data:\n+        raise HTTPException(status_code=400, detail=\"report_type and report_data required\")\n+\n+    database.save_analysis_report(user_id, report_type, report_data, all_notes_text)\n+    return {\"success\": True}\n+\n+@app.get(\"/api/default-voices\")\n+def get_default_voices():\n+    \"\"\"Get default voice configurations\"\"\"\n+    return config.VOICE_ARCHETYPES\n+\n+@app.post(\"/api/analyze\")\n+async def analyze_api(request_data: dict):\n+    \"\"\"\n+    @@@ Analyze text and return ONE new voice comment (sync API).\n+\n+    Uses PolyCLI's sync API internally - no polling needed!\n+    \"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"analyze_text\",\n+                \"params\": request_data,\n+                \"timeout\": 30.0\n+            },\n+            timeout=35.0\n+        )\n+        return response.json()\n+\n+@app.post(\"/api/chat\")\n+async def chat_api(request_data: dict):\n+    \"\"\"\n+    @@@ Chat with a voice persona (sync API).\n+\n+    Uses PolyCLI's sync API internally - no polling needed!\n+    \"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"chat_with_voice\",\n+                \"params\": request_data,\n+                \"timeout\": 30.0\n+            },\n+            timeout=35.0\n+        )\n+        return response.json()\n+\n+@app.post(\"/api/generate-image\")\n+async def generate_image_api(request_data: dict):\n+    \"\"\"\n+    @@@ Generate artistic image from notes (sync API).\n+\n+    This may take longer (60s timeout) due to image generation.\n+    \"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"generate_daily_picture\",\n+                \"params\": request_data,\n+                \"timeout\": 60.0  # Image generation takes longer\n+            },\n+            timeout=65.0\n+        )\n+        return response.json()\n+\n+@app.post(\"/api/analyze-echoes\")\n+async def analyze_echoes_api(request_data: dict):\n+    \"\"\"Analyze recurring themes in notes (sync API).\"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"analyze_echoes\",\n+                \"params\": request_data,\n+                \"timeout\": 30.0\n+            },\n+            timeout=35.0\n+        )\n+        return response.json()\n+\n+@app.post(\"/api/analyze-traits\")\n+async def analyze_traits_api(request_data: dict):\n+    \"\"\"Analyze personality traits from notes (sync API).\"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"analyze_traits\",\n+                \"params\": request_data,\n+                \"timeout\": 30.0\n+            },\n+            timeout=35.0\n+        )\n+        return response.json()\n+\n+@app.post(\"/api/analyze-patterns\")\n+async def analyze_patterns_api(request_data: dict):\n+    \"\"\"Analyze behavioral patterns from notes (sync API).\"\"\"\n+    async with httpx.AsyncClient() as client:\n+        response = await client.post(\n+            \"http://localhost:8765/polycli/api/trigger-sync\",\n+            json={\n+                \"session_id\": \"analyze_patterns\",\n+                \"params\": request_data,\n+                \"timeout\": 30.0\n+            },\n+            timeout=35.0\n+        )\n+        return response.json()\n+\n+# ========== Mount PolyCLI Control Panel ==========\n+\n+registry = get_registry()\n+mount_control_panel(app, registry, prefix=\"/polycli\")\n+\n+# ========== Main ==========\n+\n if __name__ == \"__main__\":\n-    # Get the global registry\n-    registry = get_registry()\n+    import uvicorn\n \n-    # Start the control panel\n     print(\"\\n\" + \"=\"*60)\n-    print(\"üé≠ Stateless Voice Analysis Server\")\n+    print(\"üé≠ Ink & Memory FastAPI Server\")\n     print(\"=\"*60)\n-\n-    # Monkey-patch to add /api/default-voices endpoint\n-    server, thread = registry.serve_control_panel(port=8765)\n-\n-    original_do_get = server.RequestHandlerClass.do_GET\n-    def patched_do_get(handler_self):\n-        if handler_self.path == \"/api/default-voices\":\n-            import json\n-            body = json.dumps(config.VOICE_ARCHETYPES).encode(\"utf-8\")\n-            handler_self.send_response(200)\n-            handler_self.send_header(\"Content-Type\", \"application/json\")\n-            handler_self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n-            handler_self.end_headers()\n-            handler_self.wfile.write(body)\n-        else:\n-            original_do_get(handler_self)\n-\n-    server.RequestHandlerClass.do_GET = patched_do_get\n-\n-    print(\"\\nüìö Available endpoints:\")\n-    print(\"  - POST /api/trigger\")\n-    print(\"    Body: {\\\"session_id\\\": \\\"analyze_text\\\", \\\"params\\\": {\\\"text\\\": \\\"...\\\", \\\"applied_comments\\\": [...]}}\")\n-    print(\"    Body: {\\\"session_id\\\": \\\"chat_with_voice\\\", \\\"params\\\": {\\\"voice_name\\\": \\\"...\\\", \\\"user_message\\\": \\\"...\\\", ...}}\")\n-    print(\"  - GET /api/default-voices\")\n-    print(\"\\n\" + \"=\"*60 + \"\\n\")\n-\n-    # Keep server running\n-    try:\n-        while True:\n-            time.sleep(1)\n-    except KeyboardInterrupt:\n-        print(\"\\n\\nüëã Shutting down...\")\n\\ No newline at end of file\n+    print(\"\\nüìö API Endpoints:\")\n+    print(\"  Clean API:\")\n+    print(\"    POST /api/analyze         - Analyze text (sync)\")\n+    print(\"    POST /api/chat            - Chat with voice (sync)\")\n+    print(\"    POST /api/generate-image  - Generate image (sync)\")\n+    print(\"    POST /api/analyze-echoes  - Find themes (sync)\")\n+    print(\"    POST /api/analyze-traits  - Identify traits (sync)\")\n+    print(\"    POST /api/analyze-patterns - Find patterns (sync)\")\n+    print(\"    GET  /api/default-voices  - Get voice configs\")\n+    print(\"\\n  PolyCLI Control Panel:\")\n+    print(\"    /polycli                  - Control panel UI\")\n+    print(\"    /polycli/api/trigger-sync - Direct sync API\")\n+    print(\"\\n  Documentation:\")\n+    print(\"    /docs                     - Auto-generated API docs\")\n+    print(\"=\"*60 + \"\\n\")\n+\n+    uvicorn.run(app, host=\"127.0.0.1\", port=8765)"
    },
    {
      "sha": "c14b2ec683a7cda8221e9a2f592cb4210db3bbe2",
      "filename": "backend/server_old.py",
      "status": "added",
      "additions": 498,
      "deletions": 0,
      "changes": 498,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fserver_old.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Fserver_old.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Fserver_old.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,498 @@\n+#!/usr/bin/env python3\n+\"\"\"Stateless voice analysis server - no state tracking, just returns new comments.\"\"\"\n+\n+import time\n+from polycli.orchestration.session_registry import session_def, get_registry\n+from polycli import PolyAgent\n+from stateless_analyzer import analyze_stateless\n+import config\n+from proxy_config import get_image_api_proxies\n+\n+@session_def(\n+    name=\"Chat with Voice\",\n+    description=\"Have a conversation with a specific inner voice persona\",\n+    params={\n+        \"voice_name\": {\"type\": \"str\"},\n+        \"voice_config\": {\"type\": \"dict\"},\n+        \"conversation_history\": {\"type\": \"list\"},\n+        \"user_message\": {\"type\": \"str\"},\n+        \"original_text\": {\"type\": \"str\"},\n+        \"meta_prompt\": {\"type\": \"str\"},\n+        \"state_prompt\": {\"type\": \"str\"}\n+    },\n+    category=\"Chat\"\n+)\n+def chat_with_voice(voice_name: str, voice_config: dict, conversation_history: list, user_message: str, original_text: str = \"\", meta_prompt: str = \"\", state_prompt: str = \"\"):\n+    \"\"\"\n+    Chat with a specific voice persona.\n+\n+    Args:\n+        voice_name: Name of the voice (e.g., \"Logic\", \"Drama\")\n+        voice_config: Voice configuration with tagline, icon, color\n+        conversation_history: Previous messages in the conversation\n+        user_message: The user's new message\n+        original_text: The user's original writing text\n+        meta_prompt: Additional instructions that apply to all voices\n+\n+    Returns:\n+        Dictionary with assistant's response\n+    \"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üí¨ chat_with_voice() called\")\n+    print(f\"   Voice: {voice_name}\")\n+    print(f\"   User message: {user_message}\")\n+    print(f\"   History length: {len(conversation_history)}\")\n+    print(f\"   Meta prompt: {repr(meta_prompt)[:100]}\")\n+    print(f\"   State prompt: {repr(state_prompt)[:100]}\")\n+    print(f\"{'='*60}\\n\")\n+\n+    agent = PolyAgent(id=f\"voice-chat-{voice_name.lower()}\")\n+\n+    # Ensure voice_config is a dict\n+    if not isinstance(voice_config, dict):\n+        print(f\"‚ö†Ô∏è  voice_config is not a dict: {type(voice_config)}, using default\")\n+        voice_config = {\"tagline\": f\"{voice_name} voice from Disco Elysium\"}\n+\n+    # Build system prompt for this voice\n+    system_prompt = f\"\"\"You are {voice_name}, an inner voice archetype from Disco Elysium.\n+\n+Your character: {voice_config.get('tagline', '')}\n+\n+Respond in character as {voice_name}. Be concise (1-3 sentences). Stay true to your archetype.\n+Use the conversation context but focus on your unique perspective.\"\"\"\n+\n+    # Add original writing area text if available\n+    if original_text and original_text.strip():\n+        system_prompt += f\"\"\"\n+\n+Context: The user is writing this text:\n+---\n+{original_text.strip()}\n+---\n+\n+Your initial comment was about this text. Keep this context in mind when responding to the user's questions.\"\"\"\n+\n+    # Add meta prompt if available\n+    if meta_prompt and meta_prompt.strip():\n+        system_prompt += f\"\"\"\n+\n+Additional instructions:\n+{meta_prompt.strip()}\"\"\"\n+\n+    # @@@ Add state prompt if available (between meta and voice-specific)\n+    if state_prompt and state_prompt.strip():\n+        system_prompt += f\"\"\"\n+\n+User's current state:\n+{state_prompt.strip()}\"\"\"\n+\n+    # Build full prompt with conversation history\n+    prompt = system_prompt + \"\\n\\nConversation history:\\n\"\n+\n+    # Add conversation history\n+    for msg in conversation_history:\n+        role_label = \"User\" if msg[\"role\"] == \"user\" else voice_name\n+        prompt += f\"\\n{role_label}: {msg['content']}\"\n+\n+    # Add user's new message\n+    prompt += f\"\\n\\nUser: {user_message}\\n\\n{voice_name}:\"\n+\n+    # Get response from LLM\n+    result = agent.run(prompt, model=\"gpt-4o-dou\", cli=\"no-tools\", tracked=True)\n+\n+    if not result.is_success or not result.content:\n+        response = \"...\"\n+    else:\n+        response = result.content\n+\n+    print(f\"‚úÖ Got response: {response[:100]}...\")\n+\n+    return {\n+        \"response\": response,\n+        \"voice_name\": voice_name\n+    }\n+\n+@session_def(\n+    name=\"Analyze Voices\",\n+    description=\"Get one new voice comment for text\",\n+    params={\n+        \"text\": {\"type\": \"str\"},\n+        \"session_id\": {\"type\": \"str\"},\n+        \"voices\": {\"type\": \"dict\"},\n+        \"applied_comments\": {\"type\": \"list\"},\n+        \"meta_prompt\": {\"type\": \"str\"},\n+        \"state_prompt\": {\"type\": \"str\"}\n+    },\n+    category=\"Analysis\"\n+)\n+def analyze_text(text: str, session_id: str, voices: dict = None, applied_comments: list = None, meta_prompt: str = \"\", state_prompt: str = \"\", overlapped_phrases: list = None):\n+    \"\"\"\n+    Stateless analysis - returns ONE new comment based on text and applied comments.\n+\n+    Args:\n+        text: Text to analyze (should be complete sentences only)\n+        session_id: Session ID (for future use)\n+        voices: Voice configuration\n+        applied_comments: List of already applied comments (to avoid duplicates)\n+        meta_prompt: Additional instructions that apply to all voices\n+        state_prompt: User's current emotional state prompt\n+        overlapped_phrases: Phrases that were rejected due to overlap (feedback loop)\n+\n+    Returns:\n+        Dictionary with single new voice (or empty list)\n+    \"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üéØ Stateless analyze_text() called\")\n+    print(f\"   Text: {text[:100]}...\")\n+    print(f\"   Applied comments: {len(applied_comments or [])}\")\n+    print(f\"   Overlapped phrases: {len(overlapped_phrases or [])}\")\n+    print(f\"   Meta prompt: {repr(meta_prompt)[:100]}\")\n+    print(f\"   State prompt: {repr(state_prompt)[:100]}\")\n+    print(f\"{'='*60}\\n\")\n+\n+    agent = PolyAgent(id=\"voice-analyzer\")\n+\n+    # Get voices from stateless analyzer\n+    result = analyze_stateless(agent, text, applied_comments or [], voices, meta_prompt, state_prompt, overlapped_phrases or [])\n+\n+    print(f\"‚úÖ Returning {result['new_voices_added']} new voice(s)\")\n+\n+    return {\n+        \"voices\": result[\"voices\"],\n+        \"new_voices_added\": result[\"new_voices_added\"],\n+        \"status\": \"completed\"\n+    }\n+\n+@session_def(\n+    name=\"Analyze Echoes\",\n+    description=\"Find recurring themes and topics in all user notes\",\n+    params={\n+        \"all_notes\": {\"type\": \"str\"}\n+    },\n+    category=\"Analysis\"\n+)\n+def analyze_echoes(all_notes: str):\n+    \"\"\"Analyze recurring themes and topics across all notes.\"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üîÑ analyze_echoes() called\")\n+    print(f\"   Notes length: {len(all_notes)} chars\")\n+    print(f\"{'='*60}\\n\")\n+\n+    agent = PolyAgent(id=\"echoes-analyzer\")\n+\n+    prompt = f\"\"\"Analyze these personal notes and identify recurring themes, topics, or concerns that keep appearing.\n+\n+Notes:\n+---\n+{all_notes}\n+---\n+\n+Find 3-5 echoes (recurring themes) that appear across different entries. For each echo:\n+- Give it a short title (2-4 words)\n+- Explain what pattern you see\n+- Quote 2-3 specific examples from the notes\n+\n+Format as a JSON array:\n+[\n+  {{\"title\": \"...\", \"description\": \"...\", \"examples\": [\"quote1\", \"quote2\", \"quote3\"]}},\n+  ...\n+]\n+\n+Return ONLY the JSON array, no other text.\"\"\"\n+\n+    result = agent.run(prompt, model=\"gpt-4o-dou\", cli=\"no-tools\", tracked=True)\n+\n+    if not result.is_success or not result.content:\n+        return {\"echoes\": []}\n+\n+    try:\n+        import json\n+        echoes = json.loads(result.content.strip())\n+        return {\"echoes\": echoes}\n+    except:\n+        return {\"echoes\": []}\n+\n+@session_def(\n+    name=\"Analyze Traits\",\n+    description=\"Identify personality traits and characteristics from user notes\",\n+    params={\n+        \"all_notes\": {\"type\": \"str\"}\n+    },\n+    category=\"Analysis\"\n+)\n+def analyze_traits(all_notes: str):\n+    \"\"\"Analyze personality traits from all notes.\"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üë§ analyze_traits() called\")\n+    print(f\"   Notes length: {len(all_notes)} chars\")\n+    print(f\"{'='*60}\\n\")\n+\n+    agent = PolyAgent(id=\"traits-analyzer\")\n+\n+    prompt = f\"\"\"Analyze these personal notes and identify personality traits and characteristics.\n+\n+Notes:\n+---\n+{all_notes}\n+---\n+\n+Identify 4-6 personality traits that are evident from the writing. For each trait:\n+- Give it a name (1-2 words)\n+- Rate the strength (1-5)\n+- Explain why you see this trait with specific examples\n+\n+Format as a JSON array:\n+[\n+  {{\"trait\": \"...\", \"strength\": 4, \"evidence\": \"...\"}},\n+  ...\n+]\n+\n+Return ONLY the JSON array, no other text.\"\"\"\n+\n+    result = agent.run(prompt, model=\"gpt-4o-dou\", cli=\"no-tools\", tracked=True)\n+\n+    if not result.is_success or not result.content:\n+        return {\"traits\": []}\n+\n+    try:\n+        import json\n+        traits = json.loads(result.content.strip())\n+        return {\"traits\": traits}\n+    except:\n+        return {\"traits\": []}\n+\n+@session_def(\n+    name=\"Analyze Patterns\",\n+    description=\"Identify behavioral patterns and habits from user notes\",\n+    params={\n+        \"all_notes\": {\"type\": \"str\"}\n+    },\n+    category=\"Analysis\"\n+)\n+def analyze_patterns(all_notes: str):\n+    \"\"\"Analyze behavioral patterns from all notes.\"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üîç analyze_patterns() called\")\n+    print(f\"   Notes length: {len(all_notes)} chars\")\n+    print(f\"{'='*60}\\n\")\n+\n+    agent = PolyAgent(id=\"patterns-analyzer\")\n+\n+    prompt = f\"\"\"Analyze these personal notes and identify behavioral patterns or habits.\n+\n+Notes:\n+---\n+{all_notes}\n+---\n+\n+Identify 3-5 behavioral patterns or habits. For each pattern:\n+- Give it a descriptive name\n+- Describe the pattern\n+- Note the frequency/context when it appears\n+\n+Format as a JSON array:\n+[\n+  {{\"pattern\": \"...\", \"description\": \"...\", \"frequency\": \"...\"}},\n+  ...\n+]\n+\n+Return ONLY the JSON array, no other text.\"\"\"\n+\n+    result = agent.run(prompt, model=\"gpt-4o-dou\", cli=\"no-tools\", tracked=True)\n+\n+    if not result.is_success or not result.content:\n+        return {\"patterns\": []}\n+\n+    try:\n+        import json\n+        patterns = json.loads(result.content.strip())\n+        return {\"patterns\": patterns}\n+    except:\n+        return {\"patterns\": []}\n+\n+@session_def(\n+    name=\"Generate Daily Picture\",\n+    description=\"Generate an artistic image based on user's daily notes\",\n+    params={\n+        \"all_notes\": {\"type\": \"str\"}\n+    },\n+    category=\"Creative\"\n+)\n+def generate_daily_picture(all_notes: str):\n+    \"\"\"Generate an image based on the essence of user's daily notes.\n+\n+    Uses a two-step process:\n+    1. LLM analyzes notes and creates artistic image description\n+    2. Image generation model creates the image\n+    \"\"\"\n+    print(f\"\\n{'='*60}\")\n+    print(f\"üé® generate_daily_picture() called\")\n+    print(f\"   Notes length: {len(all_notes)} chars\")\n+    print(f\"{'='*60}\\n\")\n+\n+    import requests\n+\n+    # @@@ Step 1: Convert notes to artistic image description using Claude Haiku\n+\n+    description_prompt = f\"\"\"Read these personal notes and create a vivid, artistic image description that captures the essence, mood, and themes.\n+\n+Notes:\n+---\n+{all_notes}\n+---\n+\n+Create a detailed image description (2-3 sentences) that:\n+- Captures the emotional tone and atmosphere\n+- Uses visual metaphors for abstract concepts\n+- Specifies artistic style (e.g., watercolor, impressionist, minimalist)\n+- Describes colors, lighting, composition\n+\n+Be creative and interpretive. Focus on mood and feeling, not literal representation.\n+\n+Return ONLY the image description, no other text.\"\"\"\n+\n+    print(\"üß† Creating image description from notes with Claude Haiku...\")\n+\n+    # @@@ Use proxy for GFW bypass (if configured)\n+    proxies = get_image_api_proxies()\n+\n+    claude_response = requests.post(\n+        f\"{config.IMAGE_API_ENDPOINT}/chat/completions\",\n+        headers={\n+            \"Authorization\": f\"Bearer {config.IMAGE_API_KEY}\",\n+            \"Content-Type\": \"application/json\"\n+        },\n+        json={\n+            \"model\": config.IMAGE_DESCRIPTION_MODEL,\n+            \"messages\": [{\"role\": \"user\", \"content\": description_prompt}],\n+            \"max_tokens\": config.IMAGE_DESCRIPTION_MAX_TOKENS\n+        },\n+        proxies=proxies,\n+        timeout=config.IMAGE_DESCRIPTION_TIMEOUT\n+    )\n+\n+    if claude_response.status_code != 200:\n+        return {\"image_base64\": None, \"error\": \"Failed to create image description\"}\n+\n+    claude_data = claude_response.json()\n+    image_description = claude_data.get('choices', [{}])[0].get('message', {}).get('content', '').strip()\n+\n+    if not image_description:\n+        return {\"image_base64\": None, \"error\": \"Failed to create image description\"}\n+\n+    print(f\"üìù Image description: {image_description}\")\n+\n+    # @@@ Step 2: Generate image from description with retry logic\n+    url = f\"{config.IMAGE_API_ENDPOINT}/chat/completions\"\n+    headers = {\n+        \"Authorization\": f\"Bearer {config.IMAGE_API_KEY}\",\n+        \"Content-Type\": \"application/json\"\n+    }\n+\n+    payload = {\n+        \"model\": config.IMAGE_GENERATION_MODEL,\n+        \"messages\": [\n+            {\n+                \"role\": \"user\",\n+                \"content\": image_description\n+            }\n+        ],\n+        \"max_tokens\": config.IMAGE_MAX_TOKENS\n+    }\n+\n+    # @@@ Retry logic with increasing timeouts\n+    for attempt in range(1, config.IMAGE_RETRY_MAX_ATTEMPTS + 1):\n+        try:\n+            timeout_seconds = config.IMAGE_RETRY_BASE_TIMEOUT + (attempt - 1) * config.IMAGE_RETRY_TIMEOUT_INCREMENT\n+            print(f\"üé® Generating image (attempt {attempt}/{config.IMAGE_RETRY_MAX_ATTEMPTS}, timeout={timeout_seconds}s)...\")\n+            response = requests.post(url, headers=headers, json=payload, proxies=proxies, timeout=timeout_seconds)\n+\n+            if response.status_code != 200:\n+                print(f\"‚ùå Error: {response.status_code}\")\n+                if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:\n+                    print(f\"‚è≥ Retrying in 2 seconds...\")\n+                    import time\n+                    time.sleep(2)\n+                    continue\n+                return {\"image_base64\": None, \"error\": \"Image generation failed\"}\n+\n+            data = response.json()\n+\n+            # Extract image from response\n+            if 'choices' in data and len(data['choices']) > 0:\n+                message = data['choices'][0].get('message', {})\n+                images = message.get('images', [])\n+\n+                if images:\n+                    image_data = images[0].get('image_url', {}).get('url', '')\n+\n+                    if image_data.startswith('data:image/png;base64,'):\n+                        # Extract base64 data (without the data URI prefix)\n+                        base64_data = image_data.split(',', 1)[1]\n+\n+                        print(f\"‚úÖ Image generated successfully\")\n+                        print(f\"   Size: {len(base64_data)} chars\")\n+\n+                        return {\n+                            \"image_base64\": base64_data,\n+                            \"prompt\": image_description  # Return the creative description\n+                        }\n+\n+            if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:\n+                print(f\"‚ö†Ô∏è No image in response, retrying...\")\n+                import time\n+                time.sleep(2)\n+                continue\n+            return {\"image_base64\": None, \"error\": \"No image in response\"}\n+\n+        except Exception as e:\n+            print(f\"‚ùå Exception on attempt {attempt}: {e}\")\n+            if attempt < config.IMAGE_RETRY_MAX_ATTEMPTS:\n+                print(f\"‚è≥ Retrying in 2 seconds...\")\n+                import time\n+                time.sleep(2)\n+                continue\n+            return {\"image_base64\": None, \"error\": str(e)}\n+\n+    return {\"image_base64\": None, \"error\": \"All retry attempts failed\"}\n+\n+if __name__ == \"__main__\":\n+    # Get the global registry\n+    registry = get_registry()\n+\n+    # Start the control panel\n+    print(\"\\n\" + \"=\"*60)\n+    print(\"üé≠ Stateless Voice Analysis Server\")\n+    print(\"=\"*60)\n+\n+    # Monkey-patch to add /api/default-voices endpoint\n+    server, thread = registry.serve_control_panel(port=8765)\n+\n+    original_do_get = server.RequestHandlerClass.do_GET\n+    def patched_do_get(handler_self):\n+        if handler_self.path == \"/api/default-voices\":\n+            import json\n+            body = json.dumps(config.VOICE_ARCHETYPES).encode(\"utf-8\")\n+            handler_self.send_response(200)\n+            handler_self.send_header(\"Content-Type\", \"application/json\")\n+            handler_self.send_header(\"Access-Control-Allow-Origin\", \"*\")\n+            handler_self.end_headers()\n+            handler_self.wfile.write(body)\n+        else:\n+            original_do_get(handler_self)\n+\n+    server.RequestHandlerClass.do_GET = patched_do_get\n+\n+    print(\"\\nüìö Available endpoints:\")\n+    print(\"  - POST /api/trigger\")\n+    print(\"    Body: {\\\"session_id\\\": \\\"analyze_text\\\", \\\"params\\\": {\\\"text\\\": \\\"...\\\", \\\"applied_comments\\\": [...]}}\")\n+    print(\"    Body: {\\\"session_id\\\": \\\"chat_with_voice\\\", \\\"params\\\": {\\\"voice_name\\\": \\\"...\\\", \\\"user_message\\\": \\\"...\\\", ...}}\")\n+    print(\"  - GET /api/default-voices\")\n+    print(\"\\n\" + \"=\"*60 + \"\\n\")\n+\n+    # Keep server running\n+    try:\n+        while True:\n+            time.sleep(1)\n+    except KeyboardInterrupt:\n+        print(\"\\n\\nüëã Shutting down...\")\n\\ No newline at end of file"
    },
    {
      "sha": "0063d0e23527a53bd795a194cc9aa42daf7b8b4b",
      "filename": "backend/test_migration.py",
      "status": "added",
      "additions": 205,
      "deletions": 0,
      "changes": 205,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Ftest_migration.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Ftest_migration.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Ftest_migration.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,205 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Test migration of real localStorage data to database.\n+\n+This script:\n+1. Loads the real_user_data.json export\n+2. Parses all localStorage data\n+3. Creates a test user\n+4. Migrates all data to database\n+5. Verifies migration success\n+\"\"\"\n+\n+import json\n+import sys\n+from datetime import datetime\n+import bcrypt\n+from database import (\n+    init_db, create_user, import_user_data,\n+    get_user_by_id, list_sessions, get_daily_pictures,\n+    get_preferences, get_analysis_reports\n+)\n+\n+def parse_localStorage_export(filepath):\n+    \"\"\"Parse the localStorage export JSON.\"\"\"\n+    print(f\"üìÇ Loading {filepath}...\")\n+\n+    with open(filepath, 'r') as f:\n+        data = json.load(f)\n+\n+    print(f\"‚úÖ Loaded {data.get('sizeEstimate', 'unknown')} of data\")\n+\n+    return data\n+\n+def extract_sessions(data):\n+    \"\"\"Extract all sessions from current session + calendar entries.\"\"\"\n+    sessions = []\n+\n+    # 1. Current session\n+    if data.get('currentSession'):\n+        current = json.loads(data['currentSession'])\n+        sessions.append({\n+            'id': 'current-session',\n+            'name': 'Current Session',\n+            'editor_state': current\n+        })\n+        print(f\"  ‚úÖ Current session: {len(current.get('cells', []))} cells\")\n+\n+    # 2. Calendar entries (each entry is a separate session)\n+    if data.get('calendarEntries'):\n+        calendar = json.loads(data['calendarEntries'])\n+\n+        for date, entries in calendar.items():\n+            for entry in entries:\n+                sessions.append({\n+                    'id': entry['id'],\n+                    'name': f\"{date} - {entry.get('firstLine', 'Untitled')}\",\n+                    'editor_state': entry['state']\n+                })\n+\n+        total_entries = sum(len(entries) for entries in calendar.values())\n+        print(f\"  ‚úÖ Calendar: {len(calendar)} days, {total_entries} entries\")\n+\n+    # 3. Old document system (if used)\n+    if data.get('oldDocument'):\n+        try:\n+            old_doc = json.loads(data['oldDocument'])\n+            if old_doc and old_doc.get('document'):\n+                sessions.append({\n+                    'id': 'old-document',\n+                    'name': 'Old Document (migrated)',\n+                    'editor_state': {'cells': [{'type': 'text', 'content': str(old_doc)}]}\n+                })\n+                print(f\"  ‚ö†Ô∏è Old document system found (migrated as text)\")\n+        except:\n+            pass\n+\n+    return sessions\n+\n+def extract_pictures(data):\n+    \"\"\"Extract daily pictures.\"\"\"\n+    pictures = []\n+\n+    if data.get('dailyPictures'):\n+        pics = json.loads(data['dailyPictures'])\n+        for pic in pics:\n+            pictures.append({\n+                'date': pic['date'],\n+                'image_base64': pic['base64'],\n+                'prompt': pic.get('prompt', '')\n+            })\n+\n+        print(f\"  ‚úÖ Pictures: {len(pictures)} images\")\n+\n+    return pictures\n+\n+def extract_preferences(data):\n+    \"\"\"Extract user preferences.\"\"\"\n+    prefs = {}\n+\n+    if data.get('voiceCustomizations'):\n+        prefs['voice_configs'] = json.loads(data['voiceCustomizations'])\n+\n+    if data.get('metaPrompt'):\n+        prefs['meta_prompt'] = data['metaPrompt']\n+\n+    if data.get('stateConfig'):\n+        prefs['state_config'] = json.loads(data['stateConfig'])\n+\n+    if data.get('selectedState'):\n+        prefs['selected_state'] = data['selectedState']\n+\n+    print(f\"  ‚úÖ Preferences: {len(prefs)} items\")\n+\n+    return prefs\n+\n+def extract_reports(data):\n+    \"\"\"Extract analysis reports.\"\"\"\n+    reports = []\n+\n+    if data.get('analysisReports'):\n+        report_list = json.loads(data['analysisReports'])\n+        for report in report_list:\n+            reports.append({\n+                'type': report.get('type', 'unknown'),\n+                'data': report.get('data', {}),\n+                'allNotes': report.get('allNotes', ''),\n+                'timestamp': report.get('timestamp', datetime.now().isoformat())\n+            })\n+\n+        print(f\"  ‚úÖ Reports: {len(reports)} analysis reports\")\n+\n+    return reports\n+\n+def test_migration():\n+    \"\"\"Run the full migration test.\"\"\"\n+    print(\"\\n\" + \"=\"*60)\n+    print(\"üß™ Testing localStorage Migration\")\n+    print(\"=\"*60 + \"\\n\")\n+\n+    # Step 1: Initialize database\n+    print(\"1Ô∏è‚É£ Initializing database...\")\n+    init_db()\n+\n+    # Step 2: Load localStorage export\n+    print(\"\\n2Ô∏è‚É£ Loading localStorage export...\")\n+    data = parse_localStorage_export('test_data/real_user_data.json')\n+\n+    # Step 3: Extract all data\n+    print(\"\\n3Ô∏è‚É£ Extracting data...\")\n+    sessions = extract_sessions(data)\n+    pictures = extract_pictures(data)\n+    preferences = extract_preferences(data)\n+    reports = extract_reports(data)\n+\n+    # Step 4: Create test user\n+    print(\"\\n4Ô∏è‚É£ Creating test user...\")\n+    password_hash = bcrypt.hashpw(b\"test123\", bcrypt.gensalt()).decode('utf-8')\n+    user_id = create_user('test@example.com', password_hash, 'Test User')\n+    print(f\"  ‚úÖ User created: ID={user_id}\")\n+\n+    # Step 5: Import all data\n+    print(\"\\n5Ô∏è‚É£ Importing data to database...\")\n+    import_user_data(user_id, sessions, pictures, preferences, reports)\n+\n+    # Step 6: Verify migration\n+    print(\"\\n6Ô∏è‚É£ Verifying migration...\")\n+\n+    user = get_user_by_id(user_id)\n+    print(f\"  ‚úÖ User: {user['email']}\")\n+\n+    db_sessions = list_sessions(user_id)\n+    print(f\"  ‚úÖ Sessions: {len(db_sessions)} (expected {len(sessions)})\")\n+\n+    db_pictures = get_daily_pictures(user_id, limit=100)\n+    print(f\"  ‚úÖ Pictures: {len(db_pictures)} (expected {len(pictures)})\")\n+\n+    db_prefs = get_preferences(user_id)\n+    if db_prefs:\n+        print(f\"  ‚úÖ Preferences: {len([k for k, v in db_prefs.items() if v is not None])} items\")\n+\n+    db_reports = get_analysis_reports(user_id, limit=100)\n+    print(f\"  ‚úÖ Reports: {len(db_reports)} (expected {len(reports)})\")\n+\n+    # Success!\n+    print(\"\\n\" + \"=\"*60)\n+    print(\"‚úÖ Migration test PASSED!\")\n+    print(\"=\"*60)\n+    print(f\"\\nMigrated:\")\n+    print(f\"  - {len(sessions)} sessions\")\n+    print(f\"  - {len(pictures)} images (freed ~{len(pictures) * 2.5:.1f}MB from localStorage!)\")\n+    print(f\"  - {len([k for k, v in preferences.items() if v])} preference items\")\n+    print(f\"  - {len(reports)} analysis reports\")\n+\n+    return True\n+\n+if __name__ == \"__main__\":\n+    try:\n+        test_migration()\n+        sys.exit(0)\n+    except Exception as e:\n+        print(f\"\\n‚ùå Migration test FAILED!\")\n+        print(f\"Error: {e}\")\n+        import traceback\n+        traceback.print_exc()\n+        sys.exit(1)"
    },
    {
      "sha": "fa3d1ab65e30c305d2bd2137a1ced03e7720ddea",
      "filename": "backend/test_real_migration.py",
      "status": "added",
      "additions": 210,
      "deletions": 0,
      "changes": 210,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Ftest_real_migration.py",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/backend%2Ftest_real_migration.py",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/backend%2Ftest_real_migration.py?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -0,0 +1,210 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Test full migration flow with real user data.\n+\n+Simulates:\n+1. User registers\n+2. User logs in\n+3. Frontend sends localStorage data\n+4. Backend imports to database\n+5. Frontend fetches data back\n+\"\"\"\n+\n+import requests\n+import json\n+\n+API_BASE = \"http://localhost:8765\"\n+\n+def test_full_migration():\n+    print(\"\\n\" + \"=\"*60)\n+    print(\"üß™ Testing Full Migration with Real Data\")\n+    print(\"=\"*60 + \"\\n\")\n+\n+    # Load real localStorage export\n+    print(\"üìÇ Loading real localStorage export...\")\n+    with open('test_data/real_user_data.json', 'r') as f:\n+        real_data = json.load(f)\n+\n+    print(f\"‚úÖ Loaded {real_data.get('sizeEstimate', 'unknown')}\")\n+    print()\n+\n+    # Step 1: Register\n+    print(\"1Ô∏è‚É£ Registering new user...\")\n+    register_response = requests.post(\n+        f\"{API_BASE}/api/register\",\n+        json={\n+            \"email\": \"realuser@example.com\",\n+            \"password\": \"password123\",\n+            \"display_name\": \"Real User\"\n+        }\n+    )\n+\n+    if register_response.status_code != 200:\n+        print(f\"‚ùå Registration failed: {register_response.text}\")\n+        return False\n+\n+    register_data = register_response.json()\n+    token = register_data['token']\n+    user_id = register_data['user']['id']\n+    print(f\"‚úÖ User registered: ID={user_id}\")\n+    print()\n+\n+    # Step 2: Import localStorage data\n+    print(\"2Ô∏è‚É£ Importing localStorage data...\")\n+\n+    # Prepare import request (match frontend localStorage keys)\n+    import_request = {\n+        \"currentSession\": real_data.get('currentSession'),\n+        \"calendarEntries\": real_data.get('calendarEntries'),\n+        \"dailyPictures\": real_data.get('dailyPictures'),\n+        \"voiceCustomizations\": real_data.get('voiceCustomizations'),\n+        \"metaPrompt\": real_data.get('metaPrompt'),\n+        \"stateConfig\": real_data.get('stateConfig'),\n+        \"selectedState\": real_data.get('selectedState'),\n+        \"analysisReports\": real_data.get('analysisReports'),\n+        \"oldDocument\": real_data.get('oldDocument')\n+    }\n+\n+    import_response = requests.post(\n+        f\"{API_BASE}/api/import-local-data\",\n+        headers={\"Authorization\": f\"Bearer {token}\"},\n+        json=import_request\n+    )\n+\n+    if import_response.status_code != 200:\n+        print(f\"‚ùå Import failed: {import_response.text}\")\n+        return False\n+\n+    import_result = import_response.json()\n+    print(f\"‚úÖ Import successful!\")\n+    print(f\"   Sessions: {import_result['imported']['sessions']}\")\n+    print(f\"   Pictures: {import_result['imported']['pictures']}\")\n+    print(f\"   Preferences: {import_result['imported']['preferences']}\")\n+    print(f\"   Reports: {import_result['imported']['reports']}\")\n+    print()\n+\n+    # Step 3: Verify - List sessions\n+    print(\"3Ô∏è‚É£ Verifying data - List sessions...\")\n+    sessions_response = requests.get(\n+        f\"{API_BASE}/api/sessions\",\n+        headers={\"Authorization\": f\"Bearer {token}\"}\n+    )\n+\n+    if sessions_response.status_code != 200:\n+        print(f\"‚ùå Failed to list sessions: {sessions_response.text}\")\n+        return False\n+\n+    sessions = sessions_response.json()['sessions']\n+    print(f\"‚úÖ Found {len(sessions)} sessions:\")\n+    for session in sessions[:3]:  # Show first 3\n+        print(f\"   - {session['name']} (updated: {session['updated_at']})\")\n+    if len(sessions) > 3:\n+        print(f\"   ... and {len(sessions) - 3} more\")\n+    print()\n+\n+    # Step 4: Verify - Get a session's full state\n+    if sessions:\n+        print(\"4Ô∏è‚É£ Fetching full session state...\")\n+        session_id = sessions[0]['id']\n+        session_response = requests.get(\n+            f\"{API_BASE}/api/sessions/{session_id}\",\n+            headers={\"Authorization\": f\"Bearer {token}\"}\n+        )\n+\n+        if session_response.status_code != 200:\n+            print(f\"‚ùå Failed to get session: {session_response.text}\")\n+            return False\n+\n+        session_data = session_response.json()\n+        editor_state = session_data['editor_state']\n+        num_cells = len(editor_state.get('cells', []))\n+        print(f\"‚úÖ Session '{session_data['name']}' has {num_cells} cells\")\n+        print()\n+\n+    # Step 5: Verify - Get pictures\n+    print(\"5Ô∏è‚É£ Verifying pictures...\")\n+    pictures_response = requests.get(\n+        f\"{API_BASE}/api/pictures?limit=10\",\n+        headers={\"Authorization\": f\"Bearer {token}\"}\n+    )\n+\n+    if pictures_response.status_code != 200:\n+        print(f\"‚ùå Failed to get pictures: {pictures_response.text}\")\n+        return False\n+\n+    pictures = pictures_response.json()['pictures']\n+    print(f\"‚úÖ Found {len(pictures)} pictures:\")\n+    for pic in pictures:\n+        size_kb = len(pic['image_base64']) / 1024\n+        print(f\"   - {pic['date']}: {size_kb:.1f} KB ({pic.get('prompt', 'no prompt')[:50]}...)\")\n+\n+    total_size_mb = sum(len(p['image_base64']) for p in pictures) / 1024 / 1024\n+    print(f\"   Total: {total_size_mb:.2f} MB (was in localStorage!)\")\n+    print()\n+\n+    # Step 6: Verify - Get preferences\n+    print(\"6Ô∏è‚É£ Verifying preferences...\")\n+    prefs_response = requests.get(\n+        f\"{API_BASE}/api/preferences\",\n+        headers={\"Authorization\": f\"Bearer {token}\"}\n+    )\n+\n+    if prefs_response.status_code != 200:\n+        print(f\"‚ùå Failed to get preferences: {prefs_response.text}\")\n+        return False\n+\n+    prefs = prefs_response.json()\n+    print(f\"‚úÖ Preferences loaded:\")\n+    if prefs.get('meta_prompt'):\n+        print(f\"   - Meta prompt: {prefs['meta_prompt'][:50]}...\")\n+    if prefs.get('selected_state'):\n+        print(f\"   - Selected state: {prefs['selected_state']}\")\n+    if prefs.get('voice_configs'):\n+        num_voices = len(prefs['voice_configs'])\n+        print(f\"   - Voice configs: {num_voices} voices\")\n+    print()\n+\n+    # Step 7: Verify - Get reports\n+    print(\"7Ô∏è‚É£ Verifying analysis reports...\")\n+    reports_response = requests.get(\n+        f\"{API_BASE}/api/reports?limit=10\",\n+        headers={\"Authorization\": f\"Bearer {token}\"}\n+    )\n+\n+    if reports_response.status_code != 200:\n+        print(f\"‚ùå Failed to get reports: {reports_response.text}\")\n+        return False\n+\n+    reports = reports_response.json()['reports']\n+    print(f\"‚úÖ Found {reports} reports:\")\n+    for report in reports:\n+        print(f\"   - {report['report_type']} (created: {report['created_at']})\")\n+    print()\n+\n+    # Success summary\n+    print(\"=\"*60)\n+    print(\"‚úÖ MIGRATION TEST PASSED!\")\n+    print(\"=\"*60)\n+    print(f\"\\nMigrated from localStorage ‚Üí SQLite:\")\n+    print(f\"  - {import_result['imported']['sessions']} sessions\")\n+    print(f\"  - {import_result['imported']['pictures']} pictures ({total_size_mb:.2f} MB freed!)\")\n+    print(f\"  - {import_result['imported']['preferences']} preference items\")\n+    print(f\"  - {import_result['imported']['reports']} analysis reports\")\n+    print(f\"\\nAll data successfully retrieved via API!\")\n+    print(\"=\"*60 + \"\\n\")\n+\n+    return True\n+\n+if __name__ == \"__main__\":\n+    try:\n+        success = test_full_migration()\n+        if success:\n+            print(\"üéâ Ready to build frontend!\")\n+        else:\n+            print(\"‚ùå Migration test failed\")\n+            exit(1)\n+    except Exception as e:\n+        print(f\"\\n‚ùå Error: {e}\")\n+        import traceback\n+        traceback.print_exc()\n+        exit(1)"
    },
    {
      "sha": "77d70c422e1bceb49dbaff2fc21c72a12b260e97",
      "filename": "frontend/src/api/voiceApi.ts",
      "status": "modified",
      "additions": 76,
      "deletions": 136,
      "changes": 212,
      "blob_url": "https://github.com/shuxueshuxue/ink-and-memory/blob/3de0a0c2093156f0c420724dbca83831d96bc879/frontend%2Fsrc%2Fapi%2FvoiceApi.ts",
      "raw_url": "https://github.com/shuxueshuxue/ink-and-memory/raw/3de0a0c2093156f0c420724dbca83831d96bc879/frontend%2Fsrc%2Fapi%2FvoiceApi.ts",
      "contents_url": "https://api.github.com/repos/shuxueshuxue/ink-and-memory/contents/frontend%2Fsrc%2Fapi%2FvoiceApi.ts?ref=3de0a0c2093156f0c420724dbca83831d96bc879",
      "patch": "@@ -1,5 +1,5 @@\n /**\n- * API client for voice analysis backend\n+ * API client for voice analysis backend - FastAPI sync API version\n  */\n \n // nginx proxies /ink-and-memory/api/* to backend (8765)\n@@ -13,14 +13,8 @@ export async function getDefaultVoices(): Promise<any> {\n   return await response.json();\n }\n \n-interface TriggerResponse {\n+interface SyncResponse {\n   success: boolean;\n-  exec_id: string;\n-}\n-\n-interface StatusResponse {\n-  exec_id: string;\n-  status: 'running' | 'completed' | 'failed';\n   result?: {\n     voices?: Array<{\n       phrase: string;\n@@ -29,7 +23,7 @@ interface StatusResponse {\n       icon: string;\n       color: string;\n     }>;\n-    new_voices_added?: number;  // @@@ Number of new voices from this LLM call\n+    new_voices_added?: number;\n     status?: string;\n     response?: string;  // For chat responses\n     voice_name?: string;  // For chat responses\n@@ -40,82 +34,45 @@ interface StatusResponse {\n     prompt?: string;  // Image generation prompt\n   };\n   error?: string;\n+  exec_id?: string;  // Still included for debugging\n }\n \n /**\n- * Trigger voice analysis session\n+ * Analyze text and return voices with metadata (sync API - no polling!)\n  */\n-export async function triggerAnalysis(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]): Promise<string> {\n-  console.log('üì§ Sending trigger request...');\n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+export async function analyzeText(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]) {\n+  console.log('üì§ Sending analyze request (sync API)...');\n+\n+  const response = await fetch(`${API_BASE}/api/analyze`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n     body: JSON.stringify({\n-      session_id: 'analyze_text',\n-      params: { text, session_id: sessionId, voices, applied_comments: appliedComments || [], meta_prompt: metaPrompt || '', state_prompt: statePrompt || '', overlapped_phrases: overlappedPhrases || [] }\n+      text,\n+      session_id: sessionId,\n+      voices,\n+      applied_comments: appliedComments || [],\n+      meta_prompt: metaPrompt || '',\n+      state_prompt: statePrompt || '',\n+      overlapped_phrases: overlappedPhrases || []\n     })\n   });\n \n-  console.log('üì• Got response, status:', response.status);\n-  const data: TriggerResponse = await response.json();\n-  console.log('üìã Parsed JSON:', data);\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got sync response:', data);\n \n   if (!data.success) {\n-    throw new Error('Failed to trigger analysis');\n-  }\n-\n-  console.log('‚úÖ Exec ID:', data.exec_id);\n-  return data.exec_id;\n-}\n-\n-/**\n- * Get analysis result (polls until completed)\n- */\n-export async function getAnalysisResult(exec_id: string): Promise<StatusResponse['result']> {\n-  // Poll every 500ms, max 2 minutes (enough for image generation)\n-  const maxAttempts = 240;\n-  let attempts = 0;\n-\n-  console.log('üîÑ Starting to poll for exec_id:', exec_id);\n-\n-  while (attempts < maxAttempts) {\n-    console.log(`üìä Polling attempt ${attempts + 1}/${maxAttempts}...`);\n-    const response = await fetch(`${API_BASE}/api/status/${exec_id}`);\n-    const data: StatusResponse = await response.json();\n-    console.log('üìä Status:', data.status);\n-\n-    if (data.status === 'completed') {\n-      console.log('‚úÖ Analysis completed!', data.result);\n-      return data.result;\n-    }\n-\n-    if (data.status === 'failed') {\n-      throw new Error(data.error || 'Analysis failed');\n-    }\n-\n-    // Still running, wait and retry\n-    await new Promise(resolve => setTimeout(resolve, 500));\n-    attempts++;\n+    throw new Error(data.error || 'Analysis failed');\n   }\n \n-  throw new Error('Analysis timeout');\n-}\n-\n-/**\n- * Analyze text and return voices with metadata (all-in-one)\n- */\n-export async function analyzeText(text: string, sessionId: string, voices?: any, appliedComments?: any[], metaPrompt?: string, statePrompt?: string, overlappedPhrases?: string[]) {\n-  const exec_id = await triggerAnalysis(text, sessionId, voices, appliedComments, metaPrompt, statePrompt, overlappedPhrases);\n-  const result = await getAnalysisResult(exec_id);\n-  // @@@ Return both voices and new_voices_added for energy refund mechanism\n+  // Return both voices and new_voices_added for energy refund mechanism\n   return {\n-    voices: result?.voices || [],\n-    new_voices_added: result?.new_voices_added ?? 0\n+    voices: data.result?.voices || [],\n+    new_voices_added: data.result?.new_voices_added ?? 0\n   };\n }\n \n /**\n- * Chat with a voice persona\n+ * Chat with a voice persona (sync API - no polling!)\n  */\n export async function chatWithVoice(\n   voiceName: string,\n@@ -126,140 +83,123 @@ export async function chatWithVoice(\n   metaPrompt?: string,\n   statePrompt?: string\n ): Promise<string> {\n-  console.log('üí¨ Sending chat request to backend...');\n+  console.log('üí¨ Sending chat request (sync API)...');\n \n-  // Trigger chat session\n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+  const response = await fetch(`${API_BASE}/api/chat`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n     body: JSON.stringify({\n-      session_id: 'chat_with_voice',\n-      params: {\n-        voice_name: voiceName,\n-        voice_config: voiceConfig,\n-        conversation_history: conversationHistory,\n-        user_message: userMessage,\n-        original_text: originalText || '',\n-        meta_prompt: metaPrompt || '',\n-        state_prompt: statePrompt || ''\n-      }\n+      voice_name: voiceName,\n+      voice_config: voiceConfig,\n+      conversation_history: conversationHistory,\n+      user_message: userMessage,\n+      original_text: originalText || '',\n+      meta_prompt: metaPrompt || '',\n+      state_prompt: statePrompt || ''\n     })\n   });\n \n-  const data: TriggerResponse = await response.json();\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got chat response:', data);\n+\n   if (!data.success) {\n-    throw new Error('Failed to trigger chat');\n+    throw new Error(data.error || 'Chat failed');\n   }\n \n-  console.log('‚úÖ Chat triggered, exec_id:', data.exec_id);\n-\n-  // Poll for result\n-  const result = await getAnalysisResult(data.exec_id);\n-  console.log('‚úÖ Got chat response:', result);\n-\n-  return result?.response || 'Sorry, I could not respond.';\n+  return data.result?.response || 'Sorry, I could not respond.';\n }\n \n /**\n- * Analyze echoes (recurring themes) from all notes\n+ * Analyze echoes (recurring themes) from all notes (sync API - no polling!)\n  */\n export async function analyzeEchoes(allNotes: string): Promise<any[]> {\n-  console.log('üîÑ Sending echoes analysis request...');\n+  console.log('üîÑ Sending echoes analysis request (sync API)...');\n \n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+  const response = await fetch(`${API_BASE}/api/analyze-echoes`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n-    body: JSON.stringify({\n-      session_id: 'analyze_echoes',\n-      params: { all_notes: allNotes }\n-    })\n+    body: JSON.stringify({ all_notes: allNotes })\n   });\n \n-  const data: TriggerResponse = await response.json();\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got echoes response:', data);\n+\n   if (!data.success) {\n-    throw new Error('Failed to trigger echoes analysis');\n+    throw new Error(data.error || 'Echoes analysis failed');\n   }\n \n-  const result = await getAnalysisResult(data.exec_id);\n-  return result?.echoes || [];\n+  return data.result?.echoes || [];\n }\n \n /**\n- * Analyze traits (personality characteristics) from all notes\n+ * Analyze traits (personality characteristics) from all notes (sync API - no polling!)\n  */\n export async function analyzeTraits(allNotes: string): Promise<any[]> {\n-  console.log('üë§ Sending traits analysis request...');\n+  console.log('üë§ Sending traits analysis request (sync API)...');\n \n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+  const response = await fetch(`${API_BASE}/api/analyze-traits`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n-    body: JSON.stringify({\n-      session_id: 'analyze_traits',\n-      params: { all_notes: allNotes }\n-    })\n+    body: JSON.stringify({ all_notes: allNotes })\n   });\n \n-  const data: TriggerResponse = await response.json();\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got traits response:', data);\n+\n   if (!data.success) {\n-    throw new Error('Failed to trigger traits analysis');\n+    throw new Error(data.error || 'Traits analysis failed');\n   }\n \n-  const result = await getAnalysisResult(data.exec_id);\n-  return result?.traits || [];\n+  return data.result?.traits || [];\n }\n \n /**\n- * Analyze patterns (behavioral patterns) from all notes\n+ * Analyze patterns (behavioral patterns) from all notes (sync API - no polling!)\n  */\n export async function analyzePatterns(allNotes: string): Promise<any[]> {\n-  console.log('üîç Sending patterns analysis request...');\n+  console.log('üîç Sending patterns analysis request (sync API)...');\n \n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+  const response = await fetch(`${API_BASE}/api/analyze-patterns`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n-    body: JSON.stringify({\n-      session_id: 'analyze_patterns',\n-      params: { all_notes: allNotes }\n-    })\n+    body: JSON.stringify({ all_notes: allNotes })\n   });\n \n-  const data: TriggerResponse = await response.json();\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got patterns response:', data);\n+\n   if (!data.success) {\n-    throw new Error('Failed to trigger patterns analysis');\n+    throw new Error(data.error || 'Patterns analysis failed');\n   }\n \n-  const result = await getAnalysisResult(data.exec_id);\n-  return result?.patterns || [];\n+  return data.result?.patterns || [];\n }\n \n /**\n- * Generate a daily picture based on user's notes\n+ * Generate a daily picture based on user's notes (sync API - no polling!)\n  */\n export async function generateDailyPicture(allNotes: string): Promise<{ image_base64: string; prompt: string }> {\n-  console.log('üé® Sending image generation request...');\n+  console.log('üé® Sending image generation request (sync API)...');\n \n-  const response = await fetch(`${API_BASE}/api/trigger`, {\n+  const response = await fetch(`${API_BASE}/api/generate-image`, {\n     method: 'POST',\n     headers: { 'Content-Type': 'application/json' },\n-    body: JSON.stringify({\n-      session_id: 'generate_daily_picture',\n-      params: { all_notes: allNotes }\n-    })\n+    body: JSON.stringify({ all_notes: allNotes })\n   });\n \n-  const data: TriggerResponse = await response.json();\n+  const data: SyncResponse = await response.json();\n+  console.log('‚úÖ Got image response:', data);\n+\n   if (!data.success) {\n-    throw new Error('Failed to trigger image generation');\n+    throw new Error(data.error || 'Image generation failed');\n   }\n \n-  const result = await getAnalysisResult(data.exec_id);\n-\n-  if (result?.image_base64) {\n+  if (data.result?.image_base64) {\n     return {\n-      image_base64: result.image_base64,\n-      prompt: result.prompt || 'Generated from your notes'\n+      image_base64: data.result.image_base64,\n+      prompt: data.result.prompt || 'Generated from your notes'\n     };\n   }\n \n-  throw new Error('Image generation failed');\n+  throw new Error('Image generation failed - no image in response');\n }"
    }
  ]
}